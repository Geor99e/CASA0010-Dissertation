{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e11e39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from linearmodels.panel import PanelOLS\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e49cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 0) Read and preprocessing\n",
    "panel = pd.read_csv(\"output/Final_panel_data.csv\", dtype={\"lsoa21cd\": str})\n",
    "panel[\"date\"] = pd.to_datetime(panel[\"date\"], errors=\"coerce\")\n",
    "\n",
    "# Distance column\n",
    "DIST_COL = \"d_net_min_km\"\n",
    "assert DIST_COL in panel.columns, f\"Missing column {DIST_COL}\"\n",
    "\n",
    "# Area & Population density\n",
    "if \"Area Sq Km\" in panel.columns:\n",
    "    panel[\"area_sq_km\"] = panel[\"Area Sq Km\"]\n",
    "elif \"area_sq_km\" not in panel.columns:\n",
    "    raise ValueError(\"The area column was not found!\")\n",
    "panel[\"pop_density\"] = panel[\"population\"] / panel[\"area_sq_km\"]\n",
    "panel.loc[~np.isfinite(panel[\"pop_density\"]), \"pop_density\"] = np.nan\n",
    "\n",
    "panel = panel[(panel[\"median_price\"] > 0) & panel[\"date\"].notna()].copy()\n",
    "\n",
    "# Main specification: Empty control variable (FE only)\n",
    "BASE_CTRLS = []  \n",
    "\n",
    "# 1) Constructing DID samples\n",
    "def build_group_did_sample(panel: pd.DataFrame,\n",
    "                           target_year: int,\n",
    "                           t1_km: float = 1.0,\n",
    "                           t2_km: float = 2.0,\n",
    "                           control_scope: str = \"cohort\",\n",
    "                           window_quarters: int | None = None):\n",
    "    \n",
    "    cohort = panel[panel[\"announcement_year\"] == target_year].copy()\n",
    "    cohort[\"treat\"] = (cohort[DIST_COL] <= t1_km).astype(int)\n",
    "\n",
    "    if control_scope == \"cohort\":\n",
    "        control = cohort[cohort[DIST_COL] >= t2_km].copy()\n",
    "    elif control_scope == \"all\":\n",
    "        control = panel[panel[DIST_COL] >= t2_km].copy()\n",
    "        control[\"treat\"] = 0\n",
    "    else:\n",
    "        raise ValueError(\"control_scope must be 'cohort' or 'all'.\")\n",
    "\n",
    "    treated = cohort[cohort[\"treat\"] == 1].copy()\n",
    "    did = pd.concat([treated, control], ignore_index=True)\n",
    "\n",
    "    # event time\n",
    "    event_date = pd.Timestamp(f\"{int(target_year)}-03-01\")\n",
    "    did[\"event_time\"] = event_date\n",
    "\n",
    "    # baseline DID \n",
    "    did[\"post\"] = (did[\"date\"] >= did[\"event_time\"]).astype(int)\n",
    "    did[\"did\"] = did[\"post\"] * did[\"treat\"]\n",
    "    did[\"log_price\"] = np.log(did[\"median_price\"])\n",
    "\n",
    "    # windows\n",
    "    if window_quarters is not None:\n",
    "        did[\"date_q\"] = pd.PeriodIndex(did[\"date\"], freq=\"Q\")\n",
    "        did[\"event_q\"] = pd.PeriodIndex(did[\"event_time\"], freq=\"Q\")\n",
    "        did[\"rel_q\"] = did[\"date_q\"].astype(int) - did[\"event_q\"].astype(int)\n",
    "        did = did[(did[\"rel_q\"] >= -window_quarters) & (did[\"rel_q\"] <= window_quarters)]\n",
    "\n",
    "    return did\n",
    "\n",
    "def enforce_not_yet_treated(did_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    df = did_df.copy()\n",
    "    ay = (df.groupby(\"lsoa21cd\")[\"announcement_year\"].max()\n",
    "            .astype(\"Int64\").replace({pd.NA: np.nan}))\n",
    "    df = df.merge(ay.rename(\"announcement_year_self\").reset_index(), on=\"lsoa21cd\", how=\"left\")\n",
    "    df[\"event_time_self\"] = pd.to_datetime(df[\"announcement_year_self\"].astype(\"Int64\").astype(str) + \"-03-01\",\n",
    "                                           errors=\"coerce\")\n",
    "    mask = ~((df[\"treat\"]==0) & df[\"event_time_self\"].notna() & (df[\"date\"] >= df[\"event_time_self\"]))\n",
    "    df = df[mask].drop(columns=[\"announcement_year_self\",\"event_time_self\"])\n",
    "    return df\n",
    "\n",
    "# 2) PSM (ATT/IPW) : Preprocessing features, weights, balanced diagnosis\n",
    "def build_pretreatment_features(did_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    pre = did_df[did_df[\"date\"] < did_df[\"event_time\"]].copy()\n",
    "    pre[\"log_price\"] = np.log(pre[\"median_price\"])\n",
    "\n",
    "    def _trend(group):\n",
    "        t = (group[\"date\"].rank(method=\"first\")).values\n",
    "        y = group[\"log_price\"].values\n",
    "        if len(y) < 3:\n",
    "            return pd.Series({\"trend_price\": np.nan})\n",
    "        b = np.polyfit(t, y, 1)[0]\n",
    "        return pd.Series({\"trend_price\": b})\n",
    "\n",
    "    pre_agg = pre.groupby(\"lsoa21cd\").agg(\n",
    "        baseline_log_price_mean=(\"log_price\", \"mean\"),\n",
    "        total_sales_mean=(\"total_sales\",\"mean\") if \"total_sales\" in pre.columns else (\"median_price\",\"size\"),\n",
    "        pop_density_mean=(\"pop_density\",\"mean\") if \"pop_density\" in pre.columns else (\"median_price\",\"size\"),\n",
    "        share_detached_mean=(\"share_detached\",\"mean\") if \"share_detached\" in pre.columns else (\"median_price\",\"size\"),\n",
    "        share_semi_detached_mean=(\"share_semi_detached\",\"mean\") if \"share_semi_detached\" in pre.columns else (\"median_price\",\"size\"),\n",
    "        share_terraced_mean=(\"share_terraced\",\"mean\") if \"share_terraced\" in pre.columns else (\"median_price\",\"size\"),\n",
    "        share_flat_mean=(\"share_flat\",\"mean\") if \"share_flat\" in pre.columns else (\"median_price\",\"size\"),\n",
    "    ).reset_index()\n",
    "\n",
    "    \n",
    "    trend = (pre.loc[:, [\"lsoa21cd\",\"date\",\"log_price\"]]\n",
    "                .groupby(\"lsoa21cd\").apply(_trend).reset_index())\n",
    "    X_pre = pre_agg.merge(trend, on=\"lsoa21cd\", how=\"left\")\n",
    "\n",
    "    # The LSOA layer handles the labeling\n",
    "    lsoa_role = did_df.groupby(\"lsoa21cd\").agg(\n",
    "        treat=(\"treat\",\"max\"),\n",
    "        ann_year=(\"announcement_year\",\"max\")\n",
    "    ).reset_index()\n",
    "    X = X_pre.merge(lsoa_role, on=\"lsoa21cd\", how=\"inner\")\n",
    "    return X\n",
    "\n",
    "def compute_psm_att_weights(X_lsoa: pd.DataFrame,\n",
    "                            feature_cols: list,\n",
    "                            trim_q=(0.01,0.99),\n",
    "                            stabilize=True,\n",
    "                            verbose=True,\n",
    "                            random_state=42) -> pd.DataFrame:\n",
    "    \n",
    "    cand = X_lsoa.dropna(subset=feature_cols + [\"treat\"]).copy()\n",
    "    if cand[\"treat\"].nunique() < 2:\n",
    "        raise ValueError(\"The PSM candidate set does not contain both treatment and control groups.\")\n",
    "\n",
    "    # imputation\n",
    "    for c in feature_cols:\n",
    "        if cand[c].isna().any():\n",
    "            cand[c] = cand[c].fillna(cand[c].median())\n",
    "\n",
    "    # standard + LR\n",
    "    pipe = make_pipeline(\n",
    "        StandardScaler(with_mean=True, with_std=True),\n",
    "        LogisticRegression(max_iter=5000, solver=\"lbfgs\", random_state=random_state)\n",
    "    )\n",
    "    pipe.fit(cand[feature_cols].values, cand[\"treat\"].values)\n",
    "    cand[\"ps\"] = pipe.predict_proba(cand[feature_cols].values)[:,1]\n",
    "\n",
    "    # Pruning extreme ps\n",
    "    lo, hi = np.quantile(cand[\"ps\"], [trim_q[0], trim_q[1]])\n",
    "    cand = cand[(cand[\"ps\"]>=lo) & (cand[\"ps\"]<=hi)].copy()\n",
    "\n",
    "    # weighted（ATT）\n",
    "    pt = cand[\"treat\"].mean()\n",
    "    base_w = cand[\"ps\"] / (1.0 - cand[\"ps\"])\n",
    "    if stabilize:\n",
    "        base_w = base_w * (pt / (1.0 - pt))\n",
    "    cand[\"w_att\"] = np.where(cand[\"treat\"]==1, 1.0, base_w)\n",
    "\n",
    "    if verbose:\n",
    "        n_t = int((cand[\"treat\"]==1).sum())\n",
    "        n_c = int((cand[\"treat\"]==0).sum())\n",
    "        ess_ctrl = (cand.loc[cand[\"treat\"]==0, \"w_att\"].sum()**2) / \\\n",
    "                   (cand.loc[cand[\"treat\"]==0, \"w_att\"]**2).sum()\n",
    "        print(f\"[PSM] Treated LSOA: {n_t}, Candidate controls: {n_c}, Ctrl ESS: {ess_ctrl:.1f}\")\n",
    "\n",
    "    return cand[[\"lsoa21cd\",\"ps\",\"w_att\",\"treat\"]].copy()\n",
    "\n",
    "def smd_unweighted(a, b):\n",
    "    m1, m0 = np.nanmean(a), np.nanmean(b)\n",
    "    s1, s0 = np.nanstd(a, ddof=1), np.nanstd(b, ddof=1)\n",
    "    return (m1-m0)/np.sqrt((s1**2+s0**2)/2)\n",
    "\n",
    "def balance_report(X_lsoa: pd.DataFrame, weights_df: pd.DataFrame, feature_cols: list):\n",
    "    df = X_lsoa.merge(weights_df[[\"lsoa21cd\",\"w_att\",\"treat\"]], on=\"lsoa21cd\", how=\"inner\", suffixes=(\"\", \"_psm\"))\n",
    "    treat_col = \"treat_psm\" if \"treat_psm\" in df.columns else (\"treat\" if \"treat\" in df.columns else None)\n",
    "    if treat_col is None:\n",
    "        raise KeyError(\"The treat column could not be found for balance diagnosis.\")\n",
    "\n",
    "    print(\"\\n[Balance] Standardized mean difference (unweighted) :\")\n",
    "    for c in feature_cols:\n",
    "        t = df.loc[df[treat_col]==1, c]; c0 = df.loc[df[treat_col]==0, c]\n",
    "        print(f\"  SMD({c}): {smd_unweighted(t, c0):.3f}\")\n",
    "\n",
    "    print(\"\\n[Balance] Comparison of weighted means (Control weighted by w_att) :\")\n",
    "    for c in feature_cols:\n",
    "        mt = df.loc[df[treat_col]==1, c].mean()\n",
    "        wc = df.loc[df[treat_col]==0, \"w_att\"]; xc = df.loc[df[treat_col]==0, c]\n",
    "        mc = np.average(xc, weights=wc) if wc.notna().any() else np.nan\n",
    "        print(f\"  Mean {c}: Treated={mt:.3f} | Control(w)={mc:.3f}\")\n",
    "\n",
    "# 3) DID/dose DID/Placebo without control variables\n",
    "def run_baseline_did(did_df: pd.DataFrame, weights_col: str | None = None):\n",
    "    df = did_df.copy().set_index([\"lsoa21cd\",\"date\"]).sort_index()\n",
    "    exog = df[[\"did\"]]  # Only DID，no controls\n",
    "    weights = None\n",
    "    if weights_col and (weights_col in df.columns):\n",
    "        w = df[weights_col].astype(float).replace([np.inf,-np.inf], np.nan).fillna(0.0)\n",
    "        w[w<0] = 0.0\n",
    "        weights = w\n",
    "    mod = PanelOLS(df[\"log_price\"], exog, entity_effects=True, time_effects=True,\n",
    "                   drop_absorbed=True, weights=weights)\n",
    "    res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "    return res\n",
    "\n",
    "def run_dose_did(did_df: pd.DataFrame, center_at_km: float = 1.0, weights_col: str | None = None):\n",
    "    df = did_df.copy()\n",
    "    df[\"d_centered\"] = df[DIST_COL] - center_at_km\n",
    "    df[\"did_cont\"] = df[\"did\"] * df[\"d_centered\"]\n",
    "    df = df.set_index([\"lsoa21cd\",\"date\"]).sort_index()\n",
    "    exog = df[[\"did\",\"did_cont\"]]  \n",
    "    weights = None\n",
    "    if weights_col and (weights_col in df.columns):\n",
    "        w = df[weights_col].astype(float).replace([np.inf,-np.inf], np.nan).fillna(0.0)\n",
    "        w[w<0] = 0.0\n",
    "        weights = w\n",
    "    mod = PanelOLS(df[\"log_price\"], exog, entity_effects=True, time_effects=True,\n",
    "                   drop_absorbed=True, weights=weights)\n",
    "    res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "    return res\n",
    "\n",
    "def run_placebo(did_df: pd.DataFrame, shift_quarters=8, weights_col: str | None = None):\n",
    "    df = did_df.copy()\n",
    "    event_q = pd.PeriodIndex(df[\"event_time\"], freq=\"Q\")\n",
    "    placebo_q = event_q - shift_quarters\n",
    "    df[\"placebo_event_time\"] = placebo_q.to_timestamp()\n",
    "    df[\"placebo_post\"] = (df[\"date\"] >= df[\"placebo_event_time\"]).astype(int)\n",
    "    df[\"placebo_did\"]  = df[\"placebo_post\"] * df[\"treat\"]\n",
    "    df[\"log_price\"] = np.log(df[\"median_price\"])\n",
    "    df = df.set_index([\"lsoa21cd\",\"date\"]).sort_index()\n",
    "    exog = df[[\"placebo_did\"]]  \n",
    "    weights = None\n",
    "    if weights_col and (weights_col in df.columns):\n",
    "        w = df[weights_col].astype(float).replace([np.inf,-np.inf], np.nan).fillna(0.0)\n",
    "        w[w<0] = 0.0\n",
    "        weights = w\n",
    "    mod = PanelOLS(df[\"log_price\"], exog, entity_effects=True, time_effects=True,\n",
    "                   drop_absorbed=True, weights=weights)\n",
    "    res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "    return res\n",
    "\n",
    "# 4) Treated-only Event Study\n",
    "def run_event_study_treated_only(df,\n",
    "                                 k_min=-8, k_max=8,\n",
    "                                 plot=True, title_suffix=\"\",\n",
    "                                 weights_col=None,\n",
    "                                 enforce_nyt=True,\n",
    "                                 window_quarters=None):\n",
    "    \n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from linearmodels.panel import PanelOLS\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1) event time\n",
    "    if \"announcement_year\" not in df.columns:\n",
    "        raise ValueError(\"The absence of announcement_year prevents the respective event time from being constructed.\")\n",
    "    df[\"announcement_year\"] = pd.to_numeric(df[\"announcement_year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    df[\"event_time_self\"] = pd.to_datetime(df[\"announcement_year\"].astype(str) + \"-03-01\",\n",
    "                                           errors=\"coerce\")\n",
    "\n",
    "    # 2) not-yet-treated \n",
    "    if enforce_nyt:\n",
    "        df = df[~((df[\"treat\"]==0) & df[\"event_time_self\"].notna() & (df[\"date\"] >= df[\"event_time_self\"]))].copy()\n",
    "\n",
    "    # 3) Calculate relative_q using the \"quarter number\" method\n",
    "    date_yq  = df[\"date\"].dt.year * 4 + df[\"date\"].dt.quarter\n",
    "    evt_mask = df[\"event_time_self\"].notna()\n",
    "    evt_yq   = pd.Series(np.nan, index=df.index, dtype=\"float64\")\n",
    "    evt_yq.loc[evt_mask] = (df.loc[evt_mask, \"event_time_self\"].dt.year * 4\n",
    "                            + df.loc[evt_mask, \"event_time_self\"].dt.quarter)\n",
    "    rel = date_yq - evt_yq\n",
    "    df[\"relative_q\"] = pd.to_numeric(rel, errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    # 4) Narrow the time window\n",
    "    if (window_quarters is not None) and np.isfinite(window_quarters):\n",
    "        W = int(window_quarters)\n",
    "        treated_in_window = (df[\"treat\"]==1) & df[\"relative_q\"].notna() & (df[\"relative_q\"].between(-W, W))\n",
    "        valid_dates = df.loc[treated_in_window, \"date\"].unique()\n",
    "        df = df[df[\"date\"].isin(valid_dates)].copy()\n",
    "\n",
    "    # 5) Generate event virtual only for treated The control is 0\n",
    "    for k in range(k_min, k_max+1):\n",
    "        mask = (df[\"treat\"]==1) & (df[\"relative_q\"] == k)\n",
    "        df[f\"ev_{k}\"] = mask.fillna(False).astype(int)\n",
    "    ev_cols = [f\"ev_{k}\" for k in range(k_min, k_max+1) if k != -1]  # k=-1 baseline period\n",
    "\n",
    "    # 6) Clean & Index & Weight\n",
    "    df = df[df[\"median_price\"] > 0].copy()\n",
    "    df[\"log_price\"] = np.log(df[\"median_price\"])\n",
    "    df = df.set_index([\"lsoa21cd\",\"date\"]).sort_index()\n",
    "\n",
    "    exog = df[ev_cols]  \n",
    "    weights = None\n",
    "    if weights_col and (weights_col in df.columns):\n",
    "        w = df[weights_col].astype(float).replace([np.inf,-np.inf], np.nan).fillna(0.0)\n",
    "        w[w<0] = 0.0\n",
    "        weights = w\n",
    "\n",
    "    # 7) Regression (TWFE)\n",
    "    mod = PanelOLS(df[\"log_price\"], exog, entity_effects=True, time_effects=True,\n",
    "                   drop_absorbed=True, weights=weights)\n",
    "    res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "\n",
    "    actual_ev = [v for v in ev_cols if v in res.params.index]\n",
    "    if not actual_ev:\n",
    "        print(\"Event items are still absorbed or under-sampled: Please check the treaty-only logic with sample coverage.\")\n",
    "        return None, None, None\n",
    "\n",
    "    # 8) Pre-trend Wald（k ≤ -2）\n",
    "    pre_vars = [v for v in actual_ev if int(v.split(\"_\")[1]) <= -2]\n",
    "    wald = None\n",
    "    if pre_vars:\n",
    "        try:\n",
    "            wald = res.wald_test([f\"{v} = 0\" for v in pre_vars])\n",
    "            print(f\"[ES treated-only] Pre-trend Wald: chi2={wald.stat:.2f}, p={wald.pval:.3g}\")\n",
    "        except Exception as e:\n",
    "            print(f\" Wald failed：{e}\")\n",
    "\n",
    "    # 9) Plot\n",
    "    fig = None\n",
    "    if plot:\n",
    "        betas = res.params.loc[actual_ev]\n",
    "        ci_df = res.conf_int().loc[actual_ev]\n",
    "        lower, upper = ci_df.iloc[:,0].values, ci_df.iloc[:,1].values\n",
    "        ks = np.array([int(v.split(\"_\")[1]) for v in actual_ev])\n",
    "        order = np.argsort(ks)\n",
    "        x, y = ks[order], betas.values[order]\n",
    "        l, u = lower[order], upper[order]\n",
    "        fig = plt.figure(figsize=(10,6))\n",
    "        plt.plot(x, y, marker=\"o\", label=\"Event-time (treated only)\")\n",
    "        plt.fill_between(x, l, u, alpha=0.25, label=\"95% CI\")\n",
    "        plt.axhline(0, color=\"black\", lw=1)\n",
    "        plt.axvline(0, color=\"red\", ls=\"--\", lw=1, label=\"Event (k=0)\")\n",
    "        ttl = \"Event Study (treated-only)\"\n",
    "        if title_suffix: ttl += f\" — \" + title_suffix\n",
    "        plt.title(ttl); plt.xlabel(\"Quarters relative to event (k)\"); plt.ylabel(\"Effect on log(price)\")\n",
    "        plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "    return res, wald, fig\n",
    "\n",
    "\n",
    "# 5)cohort vs all\n",
    "# PSM features\n",
    "psm_features = [\n",
    "    \"baseline_log_price_mean\",\"trend_price\",\n",
    "    \"total_sales_mean\",\"pop_density_mean\",\n",
    "    \"share_detached_mean\",\"share_semi_detached_mean\",\n",
    "    \"share_terraced_mean\",\"share_flat_mean\"\n",
    "]\n",
    "\n",
    "def run_full_pipeline_for_scope(control_scope: str,\n",
    "                                target_year: int,\n",
    "                                T1: float, T2: float,\n",
    "                                window_quarters: int | None):\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(f\"=== Running scope = {control_scope} | window = {('±'+str(window_quarters)+'Q') if window_quarters is not None else 'ALL'} ===\")\n",
    "\n",
    "    # A) create samples\n",
    "    did_data = build_group_did_sample(panel, target_year, T1, T2,\n",
    "                                      control_scope=control_scope,\n",
    "                                      window_quarters=window_quarters)\n",
    "    if control_scope == \"all\":\n",
    "        did_data = enforce_not_yet_treated(did_data)\n",
    "\n",
    "    # B) PSM\n",
    "    X_lsoa = build_pretreatment_features(did_data)\n",
    "    psm_df = compute_psm_att_weights(X_lsoa, psm_features, trim_q=(0.01,0.99),\n",
    "                                     stabilize=True, verbose=True)\n",
    "    balance_report(X_lsoa, psm_df, psm_features)\n",
    "\n",
    "    # C) Merging weights\n",
    "    did_w = did_data.merge(psm_df[[\"lsoa21cd\",\"w_att\"]], on=\"lsoa21cd\", how=\"inner\")\n",
    "    did_w[\"w_att\"] = did_w[\"w_att\"].fillna(0.0)\n",
    "\n",
    "    # D) Baseline DID\n",
    "    res_base_unw = run_baseline_did(did_data, weights_col=None)\n",
    "    print(\"\\n===== Baseline DID (Unweighted, no controls) — scope:\", control_scope, \"=====\")\n",
    "    print(res_base_unw.summary)\n",
    "    if \"did\" in res_base_unw.params.index:\n",
    "        print(f\"[Unweighted] Post announcement average effect: {np.exp(res_base_unw.params['did'])-1:.2%}\")\n",
    "\n",
    "    res_base_w = run_baseline_did(did_w, weights_col=\"w_att\")\n",
    "    print(\"\\n===== Baseline DID (PSM-ATT Weighted, no controls) — scope:\", control_scope, \"=====\")\n",
    "    print(res_base_w.summary)\n",
    "    if \"did\" in res_base_w.params.index:\n",
    "        print(f\"[PSM-Weighted] Post announcement average effect: {np.exp(res_base_w.params['did'])-1:.2%}\")\n",
    "\n",
    "    # E) Dose_response DID\n",
    "    res_dose_unw = run_dose_did(did_data, center_at_km=1.0, weights_col=None)\n",
    "    print(\"\\n===== Dose-Response DID (Unweighted, no controls) — scope:\", control_scope, \"=====\")\n",
    "    print(res_dose_unw.summary)\n",
    "\n",
    "    res_dose_w = run_dose_did(did_w, center_at_km=1.0, weights_col=\"w_att\")\n",
    "    print(\"\\n===== Dose-Response DID (PSM-ATT Weighted, no controls) — scope:\", control_scope, \"=====\")\n",
    "    print(res_dose_w.summary)\n",
    "    if {\"did\",\"did_cont\"}.issubset(res_dose_w.params.index):\n",
    "        delta = res_dose_w.params[\"did\"]; theta = res_dose_w.params[\"did_cont\"]\n",
    "        print(f\"[Dose DID | Weighted] The effect is at 1km: {np.exp(delta)-1:.2%}；Every +1km marginal change: {np.exp(theta)-1:.2%}\")\n",
    "\n",
    "    # F) Treated-only Event Study\n",
    "    did_es = did_w.dropna(subset=[\"announcement_year\"]).copy()\n",
    "    res_es_w, wald_pre_w, fig_w = run_event_study_treated_only(\n",
    "        did_es, k_min=-8, k_max=8,\n",
    "        title_suffix=f\"{target_year} cohort — {control_scope.upper()} control, PSM-weighted, no controls\",\n",
    "        weights_col=\"w_att\", enforce_nyt=True,\n",
    "        window_quarters=window_quarters\n",
    "    )\n",
    "    if res_es_w is None:\n",
    "        print(\"[Event Study] Skip: Event virtual is absorbed or under-sampled.\")\n",
    "\n",
    "    # G) Placebo\n",
    "    res_placebo_w = run_placebo(did_w, shift_quarters=8, weights_col=\"w_att\")\n",
    "    print(\"\\n===== Placebo DID (PSM-ATT Weighted, no controls) — scope:\", control_scope, \"=====\")\n",
    "    print(res_placebo_w.summary)\n",
    "    if \"placebo_did\" in res_placebo_w.params.index:\n",
    "        print(f\"[Placebo | Weighted] Effect of Placebo: {np.exp(res_placebo_w.params['placebo_did'])-1:.2%}\")\n",
    "\n",
    "    return {\n",
    "        \"did_data\": did_data, \"did_w\": did_w,\n",
    "        \"res_base_unw\": res_base_unw, \"res_base_w\": res_base_w,\n",
    "        \"res_dose_unw\": res_dose_unw, \"res_dose_w\": res_dose_w,\n",
    "        \"res_es_w\": res_es_w, \"res_placebo_w\": res_placebo_w\n",
    "    }\n",
    "\n",
    "# 6) Run !\n",
    "target_year = 2006\n",
    "T1, T2 = 1.0, 2.0\n",
    "WINDOW_Q = 12   \n",
    "\n",
    "results = {}\n",
    "for scope in [\"cohort\", \"all\"]:\n",
    "    results[scope] = run_full_pipeline_for_scope(scope, target_year, T1, T2, WINDOW_Q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0308a52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Read and preprocessing\n",
    "panel = pd.read_csv(\"output/Final_panel_data.csv\", dtype={\"lsoa21cd\": str})\n",
    "panel[\"date\"] = pd.to_datetime(panel[\"date\"], errors=\"coerce\")\n",
    "\n",
    "# Distance column\n",
    "DIST_COL = \"d_net_min_km\"\n",
    "assert DIST_COL in panel.columns, f\"Missing column {DIST_COL}\"\n",
    "\n",
    "# Area & Population density\n",
    "if \"Area Sq Km\" in panel.columns:\n",
    "    panel[\"area_sq_km\"] = panel[\"Area Sq Km\"]\n",
    "elif \"area_sq_km\" not in panel.columns:\n",
    "    raise ValueError(\"The area column was not found!\")\n",
    "panel[\"pop_density\"] = panel[\"population\"] / panel[\"area_sq_km\"]\n",
    "panel.loc[~np.isfinite(panel[\"pop_density\"]), \"pop_density\"] = np.nan\n",
    "\n",
    "panel = panel[(panel[\"median_price\"] > 0) & panel[\"date\"].notna()].copy()\n",
    "\n",
    "# Main specification: Empty control variable (FE only)\n",
    "BASE_CTRLS = []  \n",
    "\n",
    "# 1) Constructing DID samples\n",
    "def build_group_did_sample(panel: pd.DataFrame,\n",
    "                           target_year: int,\n",
    "                           t1_km: float = 1.0,\n",
    "                           t2_km: float = 2.0,\n",
    "                           control_scope: str = \"cohort\",\n",
    "                           window_quarters: int | None = None):\n",
    "    \n",
    "    cohort = panel[panel[\"announcement_year\"] == target_year].copy()\n",
    "    cohort[\"treat\"] = (cohort[DIST_COL] <= t1_km).astype(int)\n",
    "\n",
    "    if control_scope == \"cohort\":\n",
    "        control = cohort[cohort[DIST_COL] >= t2_km].copy()\n",
    "    elif control_scope == \"all\":\n",
    "        control = panel[panel[DIST_COL] >= t2_km].copy()\n",
    "        control[\"treat\"] = 0\n",
    "    else:\n",
    "        raise ValueError(\"control_scope must be 'cohort' or 'all'.\")\n",
    "\n",
    "    treated = cohort[cohort[\"treat\"] == 1].copy()\n",
    "    did = pd.concat([treated, control], ignore_index=True)\n",
    "\n",
    "    # event time\n",
    "    event_date = pd.Timestamp(f\"{int(target_year)}-03-01\")\n",
    "    did[\"event_time\"] = event_date\n",
    "\n",
    "    # baseline DID \n",
    "    did[\"post\"] = (did[\"date\"] >= did[\"event_time\"]).astype(int)\n",
    "    did[\"did\"] = did[\"post\"] * did[\"treat\"]\n",
    "    did[\"log_price\"] = np.log(did[\"median_price\"])\n",
    "\n",
    "    # windows\n",
    "    if window_quarters is not None:\n",
    "        did[\"date_q\"] = pd.PeriodIndex(did[\"date\"], freq=\"Q\")\n",
    "        did[\"event_q\"] = pd.PeriodIndex(did[\"event_time\"], freq=\"Q\")\n",
    "        did[\"rel_q\"] = did[\"date_q\"].astype(int) - did[\"event_q\"].astype(int)\n",
    "        did = did[(did[\"rel_q\"] >= -window_quarters) & (did[\"rel_q\"] <= window_quarters)]\n",
    "\n",
    "    return did\n",
    "\n",
    "def enforce_not_yet_treated(did_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    df = did_df.copy()\n",
    "    ay = (df.groupby(\"lsoa21cd\")[\"announcement_year\"].max()\n",
    "            .astype(\"Int64\").replace({pd.NA: np.nan}))\n",
    "    df = df.merge(ay.rename(\"announcement_year_self\").reset_index(), on=\"lsoa21cd\", how=\"left\")\n",
    "    df[\"event_time_self\"] = pd.to_datetime(df[\"announcement_year_self\"].astype(\"Int64\").astype(str) + \"-03-01\",\n",
    "                                           errors=\"coerce\")\n",
    "    mask = ~((df[\"treat\"]==0) & df[\"event_time_self\"].notna() & (df[\"date\"] >= df[\"event_time_self\"]))\n",
    "    df = df[mask].drop(columns=[\"announcement_year_self\",\"event_time_self\"])\n",
    "    return df\n",
    "\n",
    "# 2) PSM (ATT/IPW) : Preprocessing features, weights, balanced diagnosis\n",
    "def build_pretreatment_features(did_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    pre = did_df[did_df[\"date\"] < did_df[\"event_time\"]].copy()\n",
    "    pre[\"log_price\"] = np.log(pre[\"median_price\"])\n",
    "\n",
    "    def _trend(group):\n",
    "        t = (group[\"date\"].rank(method=\"first\")).values\n",
    "        y = group[\"log_price\"].values\n",
    "        if len(y) < 3:\n",
    "            return pd.Series({\"trend_price\": np.nan})\n",
    "        b = np.polyfit(t, y, 1)[0]\n",
    "        return pd.Series({\"trend_price\": b})\n",
    "\n",
    "    pre_agg = pre.groupby(\"lsoa21cd\").agg(\n",
    "        baseline_log_price_mean=(\"log_price\", \"mean\"),\n",
    "        total_sales_mean=(\"total_sales\",\"mean\") if \"total_sales\" in pre.columns else (\"median_price\",\"size\"),\n",
    "        pop_density_mean=(\"pop_density\",\"mean\") if \"pop_density\" in pre.columns else (\"median_price\",\"size\"),\n",
    "        share_detached_mean=(\"share_detached\",\"mean\") if \"share_detached\" in pre.columns else (\"median_price\",\"size\"),\n",
    "        share_semi_detached_mean=(\"share_semi_detached\",\"mean\") if \"share_semi_detached\" in pre.columns else (\"median_price\",\"size\"),\n",
    "        share_terraced_mean=(\"share_terraced\",\"mean\") if \"share_terraced\" in pre.columns else (\"median_price\",\"size\"),\n",
    "        share_flat_mean=(\"share_flat\",\"mean\") if \"share_flat\" in pre.columns else (\"median_price\",\"size\"),\n",
    "    ).reset_index()\n",
    "\n",
    "    \n",
    "    trend = (pre.loc[:, [\"lsoa21cd\",\"date\",\"log_price\"]]\n",
    "                .groupby(\"lsoa21cd\").apply(_trend).reset_index())\n",
    "    X_pre = pre_agg.merge(trend, on=\"lsoa21cd\", how=\"left\")\n",
    "\n",
    "    # The LSOA layer handles the labeling\n",
    "    lsoa_role = did_df.groupby(\"lsoa21cd\").agg(\n",
    "        treat=(\"treat\",\"max\"),\n",
    "        ann_year=(\"announcement_year\",\"max\")\n",
    "    ).reset_index()\n",
    "    X = X_pre.merge(lsoa_role, on=\"lsoa21cd\", how=\"inner\")\n",
    "    return X\n",
    "\n",
    "def compute_psm_att_weights(X_lsoa: pd.DataFrame,\n",
    "                            feature_cols: list,\n",
    "                            trim_q=(0.01,0.99),\n",
    "                            stabilize=True,\n",
    "                            verbose=True,\n",
    "                            random_state=42) -> pd.DataFrame:\n",
    "    \n",
    "    cand = X_lsoa.dropna(subset=feature_cols + [\"treat\"]).copy()\n",
    "    if cand[\"treat\"].nunique() < 2:\n",
    "        raise ValueError(\"The PSM candidate set does not contain both treatment and control groups.\")\n",
    "\n",
    "    # imputation\n",
    "    for c in feature_cols:\n",
    "        if cand[c].isna().any():\n",
    "            cand[c] = cand[c].fillna(cand[c].median())\n",
    "\n",
    "    # standard + LR\n",
    "    pipe = make_pipeline(\n",
    "        StandardScaler(with_mean=True, with_std=True),\n",
    "        LogisticRegression(max_iter=5000, solver=\"lbfgs\", random_state=random_state)\n",
    "    )\n",
    "    pipe.fit(cand[feature_cols].values, cand[\"treat\"].values)\n",
    "    cand[\"ps\"] = pipe.predict_proba(cand[feature_cols].values)[:,1]\n",
    "\n",
    "    # Pruning extreme ps\n",
    "    lo, hi = np.quantile(cand[\"ps\"], [trim_q[0], trim_q[1]])\n",
    "    cand = cand[(cand[\"ps\"]>=lo) & (cand[\"ps\"]<=hi)].copy()\n",
    "\n",
    "    # weighted（ATT）\n",
    "    pt = cand[\"treat\"].mean()\n",
    "    base_w = cand[\"ps\"] / (1.0 - cand[\"ps\"])\n",
    "    if stabilize:\n",
    "        base_w = base_w * (pt / (1.0 - pt))\n",
    "    cand[\"w_att\"] = np.where(cand[\"treat\"]==1, 1.0, base_w)\n",
    "\n",
    "    if verbose:\n",
    "        n_t = int((cand[\"treat\"]==1).sum())\n",
    "        n_c = int((cand[\"treat\"]==0).sum())\n",
    "        ess_ctrl = (cand.loc[cand[\"treat\"]==0, \"w_att\"].sum()**2) / \\\n",
    "                   (cand.loc[cand[\"treat\"]==0, \"w_att\"]**2).sum()\n",
    "        print(f\"[PSM] Treated LSOA: {n_t}, Candidate controls: {n_c}, Ctrl ESS: {ess_ctrl:.1f}\")\n",
    "\n",
    "    return cand[[\"lsoa21cd\",\"ps\",\"w_att\",\"treat\"]].copy()\n",
    "\n",
    "def smd_unweighted(a, b):\n",
    "    m1, m0 = np.nanmean(a), np.nanmean(b)\n",
    "    s1, s0 = np.nanstd(a, ddof=1), np.nanstd(b, ddof=1)\n",
    "    return (m1-m0)/np.sqrt((s1**2+s0**2)/2)\n",
    "\n",
    "def balance_report(X_lsoa: pd.DataFrame, weights_df: pd.DataFrame, feature_cols: list):\n",
    "    df = X_lsoa.merge(weights_df[[\"lsoa21cd\",\"w_att\",\"treat\"]], on=\"lsoa21cd\", how=\"inner\", suffixes=(\"\", \"_psm\"))\n",
    "    treat_col = \"treat_psm\" if \"treat_psm\" in df.columns else (\"treat\" if \"treat\" in df.columns else None)\n",
    "    if treat_col is None:\n",
    "        raise KeyError(\"The treat column could not be found for balance diagnosis.\")\n",
    "\n",
    "    print(\"\\n[Balance] Standardized mean difference (unweighted) :\")\n",
    "    for c in feature_cols:\n",
    "        t = df.loc[df[treat_col]==1, c]; c0 = df.loc[df[treat_col]==0, c]\n",
    "        print(f\"  SMD({c}): {smd_unweighted(t, c0):.3f}\")\n",
    "\n",
    "    print(\"\\n[Balance] Comparison of weighted means (Control weighted by w_att) :\")\n",
    "    for c in feature_cols:\n",
    "        mt = df.loc[df[treat_col]==1, c].mean()\n",
    "        wc = df.loc[df[treat_col]==0, \"w_att\"]; xc = df.loc[df[treat_col]==0, c]\n",
    "        mc = np.average(xc, weights=wc) if wc.notna().any() else np.nan\n",
    "        print(f\"  Mean {c}: Treated={mt:.3f} | Control(w)={mc:.3f}\")\n",
    "\n",
    "# 3) DID/dose DID/Placebo without control variables\n",
    "def run_baseline_did(did_df: pd.DataFrame, weights_col: str | None = None):\n",
    "    df = did_df.copy().set_index([\"lsoa21cd\",\"date\"]).sort_index()\n",
    "    exog = df[[\"did\"]]  # Only DID，no controls\n",
    "    weights = None\n",
    "    if weights_col and (weights_col in df.columns):\n",
    "        w = df[weights_col].astype(float).replace([np.inf,-np.inf], np.nan).fillna(0.0)\n",
    "        w[w<0] = 0.0\n",
    "        weights = w\n",
    "    mod = PanelOLS(df[\"log_price\"], exog, entity_effects=True, time_effects=True,\n",
    "                   drop_absorbed=True, weights=weights)\n",
    "    res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "    return res\n",
    "\n",
    "def run_dose_did(did_df: pd.DataFrame, center_at_km: float = 1.0, weights_col: str | None = None):\n",
    "    df = did_df.copy()\n",
    "    df[\"d_centered\"] = df[DIST_COL] - center_at_km\n",
    "    df[\"did_cont\"] = df[\"did\"] * df[\"d_centered\"]\n",
    "    df = df.set_index([\"lsoa21cd\",\"date\"]).sort_index()\n",
    "    exog = df[[\"did\",\"did_cont\"]]  \n",
    "    weights = None\n",
    "    if weights_col and (weights_col in df.columns):\n",
    "        w = df[weights_col].astype(float).replace([np.inf,-np.inf], np.nan).fillna(0.0)\n",
    "        w[w<0] = 0.0\n",
    "        weights = w\n",
    "    mod = PanelOLS(df[\"log_price\"], exog, entity_effects=True, time_effects=True,\n",
    "                   drop_absorbed=True, weights=weights)\n",
    "    res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "    return res\n",
    "\n",
    "def run_placebo(did_df: pd.DataFrame, shift_quarters=8, weights_col: str | None = None):\n",
    "    df = did_df.copy()\n",
    "    event_q = pd.PeriodIndex(df[\"event_time\"], freq=\"Q\")\n",
    "    placebo_q = event_q - shift_quarters\n",
    "    df[\"placebo_event_time\"] = placebo_q.to_timestamp()\n",
    "    df[\"placebo_post\"] = (df[\"date\"] >= df[\"placebo_event_time\"]).astype(int)\n",
    "    df[\"placebo_did\"]  = df[\"placebo_post\"] * df[\"treat\"]\n",
    "    df[\"log_price\"] = np.log(df[\"median_price\"])\n",
    "    df = df.set_index([\"lsoa21cd\",\"date\"]).sort_index()\n",
    "    exog = df[[\"placebo_did\"]]  \n",
    "    weights = None\n",
    "    if weights_col and (weights_col in df.columns):\n",
    "        w = df[weights_col].astype(float).replace([np.inf,-np.inf], np.nan).fillna(0.0)\n",
    "        w[w<0] = 0.0\n",
    "        weights = w\n",
    "    mod = PanelOLS(df[\"log_price\"], exog, entity_effects=True, time_effects=True,\n",
    "                   drop_absorbed=True, weights=weights)\n",
    "    res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "    return res\n",
    "\n",
    "# 4) Treated-only Event Study\n",
    "def run_event_study_treated_only(df,\n",
    "                                 k_min=-8, k_max=8,\n",
    "                                 plot=True, title_suffix=\"\",\n",
    "                                 weights_col=None,\n",
    "                                 enforce_nyt=True,\n",
    "                                 window_quarters=None):\n",
    "    \n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from linearmodels.panel import PanelOLS\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1) event time\n",
    "    if \"announcement_year\" not in df.columns:\n",
    "        raise ValueError(\"The absence of announcement_year prevents the respective event time from being constructed.\")\n",
    "    df[\"announcement_year\"] = pd.to_numeric(df[\"announcement_year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    df[\"event_time_self\"] = pd.to_datetime(df[\"announcement_year\"].astype(str) + \"-03-01\",\n",
    "                                           errors=\"coerce\")\n",
    "\n",
    "    # 2) not-yet-treated \n",
    "    if enforce_nyt:\n",
    "        df = df[~((df[\"treat\"]==0) & df[\"event_time_self\"].notna() & (df[\"date\"] >= df[\"event_time_self\"]))].copy()\n",
    "\n",
    "    # 3) Calculate relative_q using the \"quarter number\" method\n",
    "    date_yq  = df[\"date\"].dt.year * 4 + df[\"date\"].dt.quarter\n",
    "    evt_mask = df[\"event_time_self\"].notna()\n",
    "    evt_yq   = pd.Series(np.nan, index=df.index, dtype=\"float64\")\n",
    "    evt_yq.loc[evt_mask] = (df.loc[evt_mask, \"event_time_self\"].dt.year * 4\n",
    "                            + df.loc[evt_mask, \"event_time_self\"].dt.quarter)\n",
    "    rel = date_yq - evt_yq\n",
    "    df[\"relative_q\"] = pd.to_numeric(rel, errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    # 4) Narrow the time window\n",
    "    if (window_quarters is not None) and np.isfinite(window_quarters):\n",
    "        W = int(window_quarters)\n",
    "        treated_in_window = (df[\"treat\"]==1) & df[\"relative_q\"].notna() & (df[\"relative_q\"].between(-W, W))\n",
    "        valid_dates = df.loc[treated_in_window, \"date\"].unique()\n",
    "        df = df[df[\"date\"].isin(valid_dates)].copy()\n",
    "\n",
    "    # 5) Generate event virtual only for treated The control is 0\n",
    "    for k in range(k_min, k_max+1):\n",
    "        mask = (df[\"treat\"]==1) & (df[\"relative_q\"] == k)\n",
    "        df[f\"ev_{k}\"] = mask.fillna(False).astype(int)\n",
    "    ev_cols = [f\"ev_{k}\" for k in range(k_min, k_max+1) if k != -1]  # k=-1 baseline period\n",
    "\n",
    "    # 6) Clean & Index & Weight\n",
    "    df = df[df[\"median_price\"] > 0].copy()\n",
    "    df[\"log_price\"] = np.log(df[\"median_price\"])\n",
    "    df = df.set_index([\"lsoa21cd\",\"date\"]).sort_index()\n",
    "\n",
    "    exog = df[ev_cols]  \n",
    "    weights = None\n",
    "    if weights_col and (weights_col in df.columns):\n",
    "        w = df[weights_col].astype(float).replace([np.inf,-np.inf], np.nan).fillna(0.0)\n",
    "        w[w<0] = 0.0\n",
    "        weights = w\n",
    "\n",
    "    # 7) Regression (TWFE)\n",
    "    mod = PanelOLS(df[\"log_price\"], exog, entity_effects=True, time_effects=True,\n",
    "                   drop_absorbed=True, weights=weights)\n",
    "    res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "\n",
    "    actual_ev = [v for v in ev_cols if v in res.params.index]\n",
    "    if not actual_ev:\n",
    "        print(\"Event items are still absorbed or under-sampled: Please check the treaty-only logic with sample coverage.\")\n",
    "        return None, None, None\n",
    "\n",
    "    # 8) Pre-trend Wald（k ≤ -2）\n",
    "    pre_vars = [v for v in actual_ev if int(v.split(\"_\")[1]) <= -2]\n",
    "    wald = None\n",
    "    if pre_vars:\n",
    "        try:\n",
    "            wald = res.wald_test([f\"{v} = 0\" for v in pre_vars])\n",
    "            print(f\"[ES treated-only] Pre-trend Wald: chi2={wald.stat:.2f}, p={wald.pval:.3g}\")\n",
    "        except Exception as e:\n",
    "            print(f\" Wald failed：{e}\")\n",
    "\n",
    "    # 9) Plot\n",
    "    fig = None\n",
    "    if plot:\n",
    "        betas = res.params.loc[actual_ev]\n",
    "        ci_df = res.conf_int().loc[actual_ev]\n",
    "        lower, upper = ci_df.iloc[:,0].values, ci_df.iloc[:,1].values\n",
    "        ks = np.array([int(v.split(\"_\")[1]) for v in actual_ev])\n",
    "        order = np.argsort(ks)\n",
    "        x, y = ks[order], betas.values[order]\n",
    "        l, u = lower[order], upper[order]\n",
    "        fig = plt.figure(figsize=(10,6))\n",
    "        plt.plot(x, y, marker=\"o\", label=\"Event-time (treated only)\")\n",
    "        plt.fill_between(x, l, u, alpha=0.25, label=\"95% CI\")\n",
    "        plt.axhline(0, color=\"black\", lw=1)\n",
    "        plt.axvline(0, color=\"red\", ls=\"--\", lw=1, label=\"Event (k=0)\")\n",
    "        ttl = \"Event Study (treated-only)\"\n",
    "        if title_suffix: ttl += f\" — \" + title_suffix\n",
    "        plt.title(ttl); plt.xlabel(\"Quarters relative to event (k)\"); plt.ylabel(\"Effect on log(price)\")\n",
    "        plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "    return res, wald, fig\n",
    "\n",
    "\n",
    "# 5)cohort vs all\n",
    "# PSM features\n",
    "psm_features = [\n",
    "    \"baseline_log_price_mean\",\"trend_price\",\n",
    "    \"total_sales_mean\",\"pop_density_mean\",\n",
    "    \"share_detached_mean\",\"share_semi_detached_mean\",\n",
    "    \"share_terraced_mean\",\"share_flat_mean\"\n",
    "]\n",
    "\n",
    "def run_full_pipeline_for_scope(control_scope: str,\n",
    "                                target_year: int,\n",
    "                                T1: float, T2: float,\n",
    "                                window_quarters: int | None):\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(f\"=== Running scope = {control_scope} | window = {('±'+str(window_quarters)+'Q') if window_quarters is not None else 'ALL'} ===\")\n",
    "\n",
    "    # A) create samples\n",
    "    did_data = build_group_did_sample(panel, target_year, T1, T2,\n",
    "                                      control_scope=control_scope,\n",
    "                                      window_quarters=window_quarters)\n",
    "    if control_scope == \"all\":\n",
    "        did_data = enforce_not_yet_treated(did_data)\n",
    "\n",
    "    # B) PSM\n",
    "    X_lsoa = build_pretreatment_features(did_data)\n",
    "    psm_df = compute_psm_att_weights(X_lsoa, psm_features, trim_q=(0.01,0.99),\n",
    "                                     stabilize=True, verbose=True)\n",
    "    balance_report(X_lsoa, psm_df, psm_features)\n",
    "\n",
    "    # C) Merging weights\n",
    "    did_w = did_data.merge(psm_df[[\"lsoa21cd\",\"w_att\"]], on=\"lsoa21cd\", how=\"inner\")\n",
    "    did_w[\"w_att\"] = did_w[\"w_att\"].fillna(0.0)\n",
    "\n",
    "    # D) Baseline DID\n",
    "    res_base_unw = run_baseline_did(did_data, weights_col=None)\n",
    "    print(\"\\n===== Baseline DID (Unweighted, no controls) — scope:\", control_scope, \"=====\")\n",
    "    print(res_base_unw.summary)\n",
    "    if \"did\" in res_base_unw.params.index:\n",
    "        print(f\"[Unweighted] Post announcement average effect: {np.exp(res_base_unw.params['did'])-1:.2%}\")\n",
    "\n",
    "    res_base_w = run_baseline_did(did_w, weights_col=\"w_att\")\n",
    "    print(\"\\n===== Baseline DID (PSM-ATT Weighted, no controls) — scope:\", control_scope, \"=====\")\n",
    "    print(res_base_w.summary)\n",
    "    if \"did\" in res_base_w.params.index:\n",
    "        print(f\"[PSM-Weighted] Post announcement average effect: {np.exp(res_base_w.params['did'])-1:.2%}\")\n",
    "\n",
    "    # E) Dose_response DID\n",
    "    res_dose_unw = run_dose_did(did_data, center_at_km=1.0, weights_col=None)\n",
    "    print(\"\\n===== Dose-Response DID (Unweighted, no controls) — scope:\", control_scope, \"=====\")\n",
    "    print(res_dose_unw.summary)\n",
    "\n",
    "    res_dose_w = run_dose_did(did_w, center_at_km=1.0, weights_col=\"w_att\")\n",
    "    print(\"\\n===== Dose-Response DID (PSM-ATT Weighted, no controls) — scope:\", control_scope, \"=====\")\n",
    "    print(res_dose_w.summary)\n",
    "    if {\"did\",\"did_cont\"}.issubset(res_dose_w.params.index):\n",
    "        delta = res_dose_w.params[\"did\"]; theta = res_dose_w.params[\"did_cont\"]\n",
    "        print(f\"[Dose DID | Weighted] The effect is at 1km: {np.exp(delta)-1:.2%}；Every +1km marginal change: {np.exp(theta)-1:.2%}\")\n",
    "\n",
    "    # F) Treated-only Event Study\n",
    "    did_es = did_w.dropna(subset=[\"announcement_year\"]).copy()\n",
    "    res_es_w, wald_pre_w, fig_w = run_event_study_treated_only(\n",
    "        did_es, k_min=-8, k_max=8,\n",
    "        title_suffix=f\"{target_year} cohort — {control_scope.upper()} control, PSM-weighted, no controls\",\n",
    "        weights_col=\"w_att\", enforce_nyt=True,\n",
    "        window_quarters=window_quarters\n",
    "    )\n",
    "    if res_es_w is None:\n",
    "        print(\"[Event Study] Skip: Event virtual is absorbed or under-sampled.\")\n",
    "\n",
    "    # G) Placebo\n",
    "    res_placebo_w = run_placebo(did_w, shift_quarters=8, weights_col=\"w_att\")\n",
    "    print(\"\\n===== Placebo DID (PSM-ATT Weighted, no controls) — scope:\", control_scope, \"=====\")\n",
    "    print(res_placebo_w.summary)\n",
    "    if \"placebo_did\" in res_placebo_w.params.index:\n",
    "        print(f\"[Placebo | Weighted] Effect of Placebo: {np.exp(res_placebo_w.params['placebo_did'])-1:.2%}\")\n",
    "\n",
    "    return {\n",
    "        \"did_data\": did_data, \"did_w\": did_w,\n",
    "        \"res_base_unw\": res_base_unw, \"res_base_w\": res_base_w,\n",
    "        \"res_dose_unw\": res_dose_unw, \"res_dose_w\": res_dose_w,\n",
    "        \"res_es_w\": res_es_w, \"res_placebo_w\": res_placebo_w\n",
    "    }\n",
    "\n",
    "# 6) Run !\n",
    "target_year = 2009\n",
    "T1, T2 = 1.0, 2.0\n",
    "WINDOW_Q = 12   \n",
    "\n",
    "results = {}\n",
    "for scope in [\"cohort\", \"all\"]:\n",
    "    results[scope] = run_full_pipeline_for_scope(scope, target_year, T1, T2, WINDOW_Q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912b6495",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 0) Read and preprocessing\n",
    "panel = pd.read_csv(\"output/Final_panel_data.csv\", dtype={\"lsoa21cd\": str})\n",
    "panel[\"date\"] = pd.to_datetime(panel[\"date\"], errors=\"coerce\")\n",
    "\n",
    "# Distance column\n",
    "DIST_COL = \"d_net_min_km\"\n",
    "assert DIST_COL in panel.columns, f\"Missing column {DIST_COL}\"\n",
    "\n",
    "# Area & Population density\n",
    "if \"Area Sq Km\" in panel.columns:\n",
    "    panel[\"area_sq_km\"] = panel[\"Area Sq Km\"]\n",
    "elif \"area_sq_km\" not in panel.columns:\n",
    "    raise ValueError(\"The area column was not found!\")\n",
    "panel[\"pop_density\"] = panel[\"population\"] / panel[\"area_sq_km\"]\n",
    "panel.loc[~np.isfinite(panel[\"pop_density\"]), \"pop_density\"] = np.nan\n",
    "\n",
    "panel = panel[(panel[\"median_price\"] > 0) & panel[\"date\"].notna()].copy()\n",
    "\n",
    "# Main specification: Empty control variable (FE only)\n",
    "BASE_CTRLS = []  \n",
    "\n",
    "# 1) Constructing DID samples\n",
    "def build_group_did_sample(panel: pd.DataFrame,\n",
    "                           target_year: int,\n",
    "                           t1_km: float = 1.0,\n",
    "                           t2_km: float = 2.0,\n",
    "                           control_scope: str = \"cohort\",\n",
    "                           window_quarters: int | None = None):\n",
    "    \n",
    "    cohort = panel[panel[\"announcement_year\"] == target_year].copy()\n",
    "    cohort[\"treat\"] = (cohort[DIST_COL] <= t1_km).astype(int)\n",
    "\n",
    "    if control_scope == \"cohort\":\n",
    "        control = cohort[cohort[DIST_COL] >= t2_km].copy()\n",
    "    elif control_scope == \"all\":\n",
    "        control = panel[panel[DIST_COL] >= t2_km].copy()\n",
    "        control[\"treat\"] = 0\n",
    "    else:\n",
    "        raise ValueError(\"control_scope must be 'cohort' or 'all'.\")\n",
    "\n",
    "    treated = cohort[cohort[\"treat\"] == 1].copy()\n",
    "    did = pd.concat([treated, control], ignore_index=True)\n",
    "\n",
    "    # event time\n",
    "    event_date = pd.Timestamp(f\"{int(target_year)}-03-01\")\n",
    "    did[\"event_time\"] = event_date\n",
    "\n",
    "    # baseline DID \n",
    "    did[\"post\"] = (did[\"date\"] >= did[\"event_time\"]).astype(int)\n",
    "    did[\"did\"] = did[\"post\"] * did[\"treat\"]\n",
    "    did[\"log_price\"] = np.log(did[\"median_price\"])\n",
    "\n",
    "    # windows\n",
    "    if window_quarters is not None:\n",
    "        did[\"date_q\"] = pd.PeriodIndex(did[\"date\"], freq=\"Q\")\n",
    "        did[\"event_q\"] = pd.PeriodIndex(did[\"event_time\"], freq=\"Q\")\n",
    "        did[\"rel_q\"] = did[\"date_q\"].astype(int) - did[\"event_q\"].astype(int)\n",
    "        did = did[(did[\"rel_q\"] >= -window_quarters) & (did[\"rel_q\"] <= window_quarters)]\n",
    "\n",
    "    return did\n",
    "\n",
    "def enforce_not_yet_treated(did_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    df = did_df.copy()\n",
    "    ay = (df.groupby(\"lsoa21cd\")[\"announcement_year\"].max()\n",
    "            .astype(\"Int64\").replace({pd.NA: np.nan}))\n",
    "    df = df.merge(ay.rename(\"announcement_year_self\").reset_index(), on=\"lsoa21cd\", how=\"left\")\n",
    "    df[\"event_time_self\"] = pd.to_datetime(df[\"announcement_year_self\"].astype(\"Int64\").astype(str) + \"-03-01\",\n",
    "                                           errors=\"coerce\")\n",
    "    mask = ~((df[\"treat\"]==0) & df[\"event_time_self\"].notna() & (df[\"date\"] >= df[\"event_time_self\"]))\n",
    "    df = df[mask].drop(columns=[\"announcement_year_self\",\"event_time_self\"])\n",
    "    return df\n",
    "\n",
    "# 2) PSM (ATT/IPW) : Preprocessing features, weights, balanced diagnosis\n",
    "def build_pretreatment_features(did_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    pre = did_df[did_df[\"date\"] < did_df[\"event_time\"]].copy()\n",
    "    pre[\"log_price\"] = np.log(pre[\"median_price\"])\n",
    "\n",
    "    def _trend(group):\n",
    "        t = (group[\"date\"].rank(method=\"first\")).values\n",
    "        y = group[\"log_price\"].values\n",
    "        if len(y) < 3:\n",
    "            return pd.Series({\"trend_price\": np.nan})\n",
    "        b = np.polyfit(t, y, 1)[0]\n",
    "        return pd.Series({\"trend_price\": b})\n",
    "\n",
    "    pre_agg = pre.groupby(\"lsoa21cd\").agg(\n",
    "        baseline_log_price_mean=(\"log_price\", \"mean\"),\n",
    "        total_sales_mean=(\"total_sales\",\"mean\") if \"total_sales\" in pre.columns else (\"median_price\",\"size\"),\n",
    "        pop_density_mean=(\"pop_density\",\"mean\") if \"pop_density\" in pre.columns else (\"median_price\",\"size\"),\n",
    "        share_detached_mean=(\"share_detached\",\"mean\") if \"share_detached\" in pre.columns else (\"median_price\",\"size\"),\n",
    "        share_semi_detached_mean=(\"share_semi_detached\",\"mean\") if \"share_semi_detached\" in pre.columns else (\"median_price\",\"size\"),\n",
    "        share_terraced_mean=(\"share_terraced\",\"mean\") if \"share_terraced\" in pre.columns else (\"median_price\",\"size\"),\n",
    "        share_flat_mean=(\"share_flat\",\"mean\") if \"share_flat\" in pre.columns else (\"median_price\",\"size\"),\n",
    "    ).reset_index()\n",
    "\n",
    "    \n",
    "    trend = (pre.loc[:, [\"lsoa21cd\",\"date\",\"log_price\"]]\n",
    "                .groupby(\"lsoa21cd\").apply(_trend).reset_index())\n",
    "    X_pre = pre_agg.merge(trend, on=\"lsoa21cd\", how=\"left\")\n",
    "\n",
    "    # The LSOA layer handles the labeling\n",
    "    lsoa_role = did_df.groupby(\"lsoa21cd\").agg(\n",
    "        treat=(\"treat\",\"max\"),\n",
    "        ann_year=(\"announcement_year\",\"max\")\n",
    "    ).reset_index()\n",
    "    X = X_pre.merge(lsoa_role, on=\"lsoa21cd\", how=\"inner\")\n",
    "    return X\n",
    "\n",
    "def compute_psm_att_weights(X_lsoa: pd.DataFrame,\n",
    "                            feature_cols: list,\n",
    "                            trim_q=(0.01,0.99),\n",
    "                            stabilize=True,\n",
    "                            verbose=True,\n",
    "                            random_state=42) -> pd.DataFrame:\n",
    "    \n",
    "    cand = X_lsoa.dropna(subset=feature_cols + [\"treat\"]).copy()\n",
    "    if cand[\"treat\"].nunique() < 2:\n",
    "        raise ValueError(\"The PSM candidate set does not contain both treatment and control groups.\")\n",
    "\n",
    "    # imputation\n",
    "    for c in feature_cols:\n",
    "        if cand[c].isna().any():\n",
    "            cand[c] = cand[c].fillna(cand[c].median())\n",
    "\n",
    "    # standard + LR\n",
    "    pipe = make_pipeline(\n",
    "        StandardScaler(with_mean=True, with_std=True),\n",
    "        LogisticRegression(max_iter=5000, solver=\"lbfgs\", random_state=random_state)\n",
    "    )\n",
    "    pipe.fit(cand[feature_cols].values, cand[\"treat\"].values)\n",
    "    cand[\"ps\"] = pipe.predict_proba(cand[feature_cols].values)[:,1]\n",
    "\n",
    "    # Pruning extreme ps\n",
    "    lo, hi = np.quantile(cand[\"ps\"], [trim_q[0], trim_q[1]])\n",
    "    cand = cand[(cand[\"ps\"]>=lo) & (cand[\"ps\"]<=hi)].copy()\n",
    "\n",
    "    # weighted（ATT）\n",
    "    pt = cand[\"treat\"].mean()\n",
    "    base_w = cand[\"ps\"] / (1.0 - cand[\"ps\"])\n",
    "    if stabilize:\n",
    "        base_w = base_w * (pt / (1.0 - pt))\n",
    "    cand[\"w_att\"] = np.where(cand[\"treat\"]==1, 1.0, base_w)\n",
    "\n",
    "    if verbose:\n",
    "        n_t = int((cand[\"treat\"]==1).sum())\n",
    "        n_c = int((cand[\"treat\"]==0).sum())\n",
    "        ess_ctrl = (cand.loc[cand[\"treat\"]==0, \"w_att\"].sum()**2) / \\\n",
    "                   (cand.loc[cand[\"treat\"]==0, \"w_att\"]**2).sum()\n",
    "        print(f\"[PSM] Treated LSOA: {n_t}, Candidate controls: {n_c}, Ctrl ESS: {ess_ctrl:.1f}\")\n",
    "\n",
    "    return cand[[\"lsoa21cd\",\"ps\",\"w_att\",\"treat\"]].copy()\n",
    "\n",
    "def smd_unweighted(a, b):\n",
    "    m1, m0 = np.nanmean(a), np.nanmean(b)\n",
    "    s1, s0 = np.nanstd(a, ddof=1), np.nanstd(b, ddof=1)\n",
    "    return (m1-m0)/np.sqrt((s1**2+s0**2)/2)\n",
    "\n",
    "def balance_report(X_lsoa: pd.DataFrame, weights_df: pd.DataFrame, feature_cols: list):\n",
    "    df = X_lsoa.merge(weights_df[[\"lsoa21cd\",\"w_att\",\"treat\"]], on=\"lsoa21cd\", how=\"inner\", suffixes=(\"\", \"_psm\"))\n",
    "    treat_col = \"treat_psm\" if \"treat_psm\" in df.columns else (\"treat\" if \"treat\" in df.columns else None)\n",
    "    if treat_col is None:\n",
    "        raise KeyError(\"The treat column could not be found for balance diagnosis.\")\n",
    "\n",
    "    print(\"\\n[Balance] Standardized mean difference (unweighted) :\")\n",
    "    for c in feature_cols:\n",
    "        t = df.loc[df[treat_col]==1, c]; c0 = df.loc[df[treat_col]==0, c]\n",
    "        print(f\"  SMD({c}): {smd_unweighted(t, c0):.3f}\")\n",
    "\n",
    "    print(\"\\n[Balance] Comparison of weighted means (Control weighted by w_att) :\")\n",
    "    for c in feature_cols:\n",
    "        mt = df.loc[df[treat_col]==1, c].mean()\n",
    "        wc = df.loc[df[treat_col]==0, \"w_att\"]; xc = df.loc[df[treat_col]==0, c]\n",
    "        mc = np.average(xc, weights=wc) if wc.notna().any() else np.nan\n",
    "        print(f\"  Mean {c}: Treated={mt:.3f} | Control(w)={mc:.3f}\")\n",
    "\n",
    "# 3) DID/dose DID/Placebo without control variables\n",
    "def run_baseline_did(did_df: pd.DataFrame, weights_col: str | None = None):\n",
    "    df = did_df.copy().set_index([\"lsoa21cd\",\"date\"]).sort_index()\n",
    "    exog = df[[\"did\"]]  # Only DID，no controls\n",
    "    weights = None\n",
    "    if weights_col and (weights_col in df.columns):\n",
    "        w = df[weights_col].astype(float).replace([np.inf,-np.inf], np.nan).fillna(0.0)\n",
    "        w[w<0] = 0.0\n",
    "        weights = w\n",
    "    mod = PanelOLS(df[\"log_price\"], exog, entity_effects=True, time_effects=True,\n",
    "                   drop_absorbed=True, weights=weights)\n",
    "    res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "    return res\n",
    "\n",
    "def run_dose_did(did_df: pd.DataFrame, center_at_km: float = 1.0, weights_col: str | None = None):\n",
    "    df = did_df.copy()\n",
    "    df[\"d_centered\"] = df[DIST_COL] - center_at_km\n",
    "    df[\"did_cont\"] = df[\"did\"] * df[\"d_centered\"]\n",
    "    df = df.set_index([\"lsoa21cd\",\"date\"]).sort_index()\n",
    "    exog = df[[\"did\",\"did_cont\"]]  \n",
    "    weights = None\n",
    "    if weights_col and (weights_col in df.columns):\n",
    "        w = df[weights_col].astype(float).replace([np.inf,-np.inf], np.nan).fillna(0.0)\n",
    "        w[w<0] = 0.0\n",
    "        weights = w\n",
    "    mod = PanelOLS(df[\"log_price\"], exog, entity_effects=True, time_effects=True,\n",
    "                   drop_absorbed=True, weights=weights)\n",
    "    res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "    return res\n",
    "\n",
    "def run_placebo(did_df: pd.DataFrame, shift_quarters=8, weights_col: str | None = None):\n",
    "    df = did_df.copy()\n",
    "    event_q = pd.PeriodIndex(df[\"event_time\"], freq=\"Q\")\n",
    "    placebo_q = event_q - shift_quarters\n",
    "    df[\"placebo_event_time\"] = placebo_q.to_timestamp()\n",
    "    df[\"placebo_post\"] = (df[\"date\"] >= df[\"placebo_event_time\"]).astype(int)\n",
    "    df[\"placebo_did\"]  = df[\"placebo_post\"] * df[\"treat\"]\n",
    "    df[\"log_price\"] = np.log(df[\"median_price\"])\n",
    "    df = df.set_index([\"lsoa21cd\",\"date\"]).sort_index()\n",
    "    exog = df[[\"placebo_did\"]]  \n",
    "    weights = None\n",
    "    if weights_col and (weights_col in df.columns):\n",
    "        w = df[weights_col].astype(float).replace([np.inf,-np.inf], np.nan).fillna(0.0)\n",
    "        w[w<0] = 0.0\n",
    "        weights = w\n",
    "    mod = PanelOLS(df[\"log_price\"], exog, entity_effects=True, time_effects=True,\n",
    "                   drop_absorbed=True, weights=weights)\n",
    "    res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "    return res\n",
    "\n",
    "# 4) Treated-only Event Study\n",
    "def run_event_study_treated_only(df,\n",
    "                                 k_min=-8, k_max=8,\n",
    "                                 plot=True, title_suffix=\"\",\n",
    "                                 weights_col=None,\n",
    "                                 enforce_nyt=True,\n",
    "                                 window_quarters=None):\n",
    "    \n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from linearmodels.panel import PanelOLS\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1) event time\n",
    "    if \"announcement_year\" not in df.columns:\n",
    "        raise ValueError(\"The absence of announcement_year prevents the respective event time from being constructed.\")\n",
    "    df[\"announcement_year\"] = pd.to_numeric(df[\"announcement_year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    df[\"event_time_self\"] = pd.to_datetime(df[\"announcement_year\"].astype(str) + \"-03-01\",\n",
    "                                           errors=\"coerce\")\n",
    "\n",
    "    # 2) not-yet-treated \n",
    "    if enforce_nyt:\n",
    "        df = df[~((df[\"treat\"]==0) & df[\"event_time_self\"].notna() & (df[\"date\"] >= df[\"event_time_self\"]))].copy()\n",
    "\n",
    "    # 3) Calculate relative_q using the \"quarter number\" method\n",
    "    date_yq  = df[\"date\"].dt.year * 4 + df[\"date\"].dt.quarter\n",
    "    evt_mask = df[\"event_time_self\"].notna()\n",
    "    evt_yq   = pd.Series(np.nan, index=df.index, dtype=\"float64\")\n",
    "    evt_yq.loc[evt_mask] = (df.loc[evt_mask, \"event_time_self\"].dt.year * 4\n",
    "                            + df.loc[evt_mask, \"event_time_self\"].dt.quarter)\n",
    "    rel = date_yq - evt_yq\n",
    "    df[\"relative_q\"] = pd.to_numeric(rel, errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    # 4) Narrow the time window\n",
    "    if (window_quarters is not None) and np.isfinite(window_quarters):\n",
    "        W = int(window_quarters)\n",
    "        treated_in_window = (df[\"treat\"]==1) & df[\"relative_q\"].notna() & (df[\"relative_q\"].between(-W, W))\n",
    "        valid_dates = df.loc[treated_in_window, \"date\"].unique()\n",
    "        df = df[df[\"date\"].isin(valid_dates)].copy()\n",
    "\n",
    "    # 5) Generate event virtual only for treated The control is 0\n",
    "    for k in range(k_min, k_max+1):\n",
    "        mask = (df[\"treat\"]==1) & (df[\"relative_q\"] == k)\n",
    "        df[f\"ev_{k}\"] = mask.fillna(False).astype(int)\n",
    "    ev_cols = [f\"ev_{k}\" for k in range(k_min, k_max+1) if k != -1]  # k=-1 baseline period\n",
    "\n",
    "    # 6) Clean & Index & Weight\n",
    "    df = df[df[\"median_price\"] > 0].copy()\n",
    "    df[\"log_price\"] = np.log(df[\"median_price\"])\n",
    "    df = df.set_index([\"lsoa21cd\",\"date\"]).sort_index()\n",
    "\n",
    "    exog = df[ev_cols]  \n",
    "    weights = None\n",
    "    if weights_col and (weights_col in df.columns):\n",
    "        w = df[weights_col].astype(float).replace([np.inf,-np.inf], np.nan).fillna(0.0)\n",
    "        w[w<0] = 0.0\n",
    "        weights = w\n",
    "\n",
    "    # 7) Regression (TWFE)\n",
    "    mod = PanelOLS(df[\"log_price\"], exog, entity_effects=True, time_effects=True,\n",
    "                   drop_absorbed=True, weights=weights)\n",
    "    res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "\n",
    "    actual_ev = [v for v in ev_cols if v in res.params.index]\n",
    "    if not actual_ev:\n",
    "        print(\"Event items are still absorbed or under-sampled: Please check the treaty-only logic with sample coverage.\")\n",
    "        return None, None, None\n",
    "\n",
    "    # 8) Pre-trend Wald（k ≤ -2）\n",
    "    pre_vars = [v for v in actual_ev if int(v.split(\"_\")[1]) <= -2]\n",
    "    wald = None\n",
    "    if pre_vars:\n",
    "        try:\n",
    "            wald = res.wald_test([f\"{v} = 0\" for v in pre_vars])\n",
    "            print(f\"[ES treated-only] Pre-trend Wald: chi2={wald.stat:.2f}, p={wald.pval:.3g}\")\n",
    "        except Exception as e:\n",
    "            print(f\" Wald failed：{e}\")\n",
    "\n",
    "    # 9) Plot\n",
    "    fig = None\n",
    "    if plot:\n",
    "        betas = res.params.loc[actual_ev]\n",
    "        ci_df = res.conf_int().loc[actual_ev]\n",
    "        lower, upper = ci_df.iloc[:,0].values, ci_df.iloc[:,1].values\n",
    "        ks = np.array([int(v.split(\"_\")[1]) for v in actual_ev])\n",
    "        order = np.argsort(ks)\n",
    "        x, y = ks[order], betas.values[order]\n",
    "        l, u = lower[order], upper[order]\n",
    "        fig = plt.figure(figsize=(10,6))\n",
    "        plt.plot(x, y, marker=\"o\", label=\"Event-time (treated only)\")\n",
    "        plt.fill_between(x, l, u, alpha=0.25, label=\"95% CI\")\n",
    "        plt.axhline(0, color=\"black\", lw=1)\n",
    "        plt.axvline(0, color=\"red\", ls=\"--\", lw=1, label=\"Event (k=0)\")\n",
    "        ttl = \"Event Study (treated-only)\"\n",
    "        if title_suffix: ttl += f\" — \" + title_suffix\n",
    "        plt.title(ttl); plt.xlabel(\"Quarters relative to event (k)\"); plt.ylabel(\"Effect on log(price)\")\n",
    "        plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "    return res, wald, fig\n",
    "\n",
    "\n",
    "# 5)cohort vs all\n",
    "# PSM features\n",
    "psm_features = [\n",
    "    \"baseline_log_price_mean\",\"trend_price\",\n",
    "    \"total_sales_mean\",\"pop_density_mean\",\n",
    "    \"share_detached_mean\",\"share_semi_detached_mean\",\n",
    "    \"share_terraced_mean\",\"share_flat_mean\"\n",
    "]\n",
    "\n",
    "def run_full_pipeline_for_scope(control_scope: str,\n",
    "                                target_year: int,\n",
    "                                T1: float, T2: float,\n",
    "                                window_quarters: int | None):\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(f\"=== Running scope = {control_scope} | window = {('±'+str(window_quarters)+'Q') if window_quarters is not None else 'ALL'} ===\")\n",
    "\n",
    "    # A) create samples\n",
    "    did_data = build_group_did_sample(panel, target_year, T1, T2,\n",
    "                                      control_scope=control_scope,\n",
    "                                      window_quarters=window_quarters)\n",
    "    if control_scope == \"all\":\n",
    "        did_data = enforce_not_yet_treated(did_data)\n",
    "\n",
    "    # B) PSM\n",
    "    X_lsoa = build_pretreatment_features(did_data)\n",
    "    psm_df = compute_psm_att_weights(X_lsoa, psm_features, trim_q=(0.01,0.99),\n",
    "                                     stabilize=True, verbose=True)\n",
    "    balance_report(X_lsoa, psm_df, psm_features)\n",
    "\n",
    "    # C) Merging weights\n",
    "    did_w = did_data.merge(psm_df[[\"lsoa21cd\",\"w_att\"]], on=\"lsoa21cd\", how=\"inner\")\n",
    "    did_w[\"w_att\"] = did_w[\"w_att\"].fillna(0.0)\n",
    "\n",
    "    # D) Baseline DID\n",
    "    res_base_unw = run_baseline_did(did_data, weights_col=None)\n",
    "    print(\"\\n===== Baseline DID (Unweighted, no controls) — scope:\", control_scope, \"=====\")\n",
    "    print(res_base_unw.summary)\n",
    "    if \"did\" in res_base_unw.params.index:\n",
    "        print(f\"[Unweighted] Post announcement average effect: {np.exp(res_base_unw.params['did'])-1:.2%}\")\n",
    "\n",
    "    res_base_w = run_baseline_did(did_w, weights_col=\"w_att\")\n",
    "    print(\"\\n===== Baseline DID (PSM-ATT Weighted, no controls) — scope:\", control_scope, \"=====\")\n",
    "    print(res_base_w.summary)\n",
    "    if \"did\" in res_base_w.params.index:\n",
    "        print(f\"[PSM-Weighted] Post announcement average effect: {np.exp(res_base_w.params['did'])-1:.2%}\")\n",
    "\n",
    "    # E) Dose_response DID\n",
    "    res_dose_unw = run_dose_did(did_data, center_at_km=1.0, weights_col=None)\n",
    "    print(\"\\n===== Dose-Response DID (Unweighted, no controls) — scope:\", control_scope, \"=====\")\n",
    "    print(res_dose_unw.summary)\n",
    "\n",
    "    res_dose_w = run_dose_did(did_w, center_at_km=1.0, weights_col=\"w_att\")\n",
    "    print(\"\\n===== Dose-Response DID (PSM-ATT Weighted, no controls) — scope:\", control_scope, \"=====\")\n",
    "    print(res_dose_w.summary)\n",
    "    if {\"did\",\"did_cont\"}.issubset(res_dose_w.params.index):\n",
    "        delta = res_dose_w.params[\"did\"]; theta = res_dose_w.params[\"did_cont\"]\n",
    "        print(f\"[Dose DID | Weighted] The effect is at 1km: {np.exp(delta)-1:.2%}；Every +1km marginal change: {np.exp(theta)-1:.2%}\")\n",
    "\n",
    "    # F) Treated-only Event Study\n",
    "    did_es = did_w.dropna(subset=[\"announcement_year\"]).copy()\n",
    "    res_es_w, wald_pre_w, fig_w = run_event_study_treated_only(\n",
    "        did_es, k_min=-8, k_max=8,\n",
    "        title_suffix=f\"{target_year} cohort — {control_scope.upper()} control, PSM-weighted, no controls\",\n",
    "        weights_col=\"w_att\", enforce_nyt=True,\n",
    "        window_quarters=window_quarters\n",
    "    )\n",
    "    if res_es_w is None:\n",
    "        print(\"[Event Study] Skip: Event virtual is absorbed or under-sampled.\")\n",
    "\n",
    "    # G) Placebo\n",
    "    res_placebo_w = run_placebo(did_w, shift_quarters=8, weights_col=\"w_att\")\n",
    "    print(\"\\n===== Placebo DID (PSM-ATT Weighted, no controls) — scope:\", control_scope, \"=====\")\n",
    "    print(res_placebo_w.summary)\n",
    "    if \"placebo_did\" in res_placebo_w.params.index:\n",
    "        print(f\"[Placebo | Weighted] Effect of Placebo: {np.exp(res_placebo_w.params['placebo_did'])-1:.2%}\")\n",
    "\n",
    "    return {\n",
    "        \"did_data\": did_data, \"did_w\": did_w,\n",
    "        \"res_base_unw\": res_base_unw, \"res_base_w\": res_base_w,\n",
    "        \"res_dose_unw\": res_dose_unw, \"res_dose_w\": res_dose_w,\n",
    "        \"res_es_w\": res_es_w, \"res_placebo_w\": res_placebo_w\n",
    "    }\n",
    "\n",
    "# 6) Run !\n",
    "target_year = 2015\n",
    "T1, T2 = 1.0, 2.0\n",
    "WINDOW_Q = 12   \n",
    "\n",
    "results = {}\n",
    "for scope in [\"cohort\", \"all\"]:\n",
    "    results[scope] = run_full_pipeline_for_scope(scope, target_year, T1, T2, WINDOW_Q)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transport-houseprice-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

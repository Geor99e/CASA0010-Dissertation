{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2d82c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from linearmodels.panel import PanelOLS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27cc77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Settings\n",
    "DIST_COL = \"d_net_min_km\"    \n",
    "ID_COL   = \"lsoa21cd\"\n",
    "DATE_COL = \"date\"\n",
    "COHORT_COL = \"announcement_year\"  \n",
    "T1, T2 = 1.0, 2.0                  \n",
    "BASE_CTRLS = [\"share_detached\",\"share_semi_detached\",\"share_terraced\",\"share_flat\",\"total_sales\",\"pop_density\"]\n",
    "\n",
    "\n",
    "# Read and preprocessing\n",
    "panel = pd.read_csv(\"output/Final_panel_data.csv\", dtype={ID_COL: str})\n",
    "panel[DATE_COL] = pd.to_datetime(panel[DATE_COL])\n",
    "\n",
    "# pop density\n",
    "if \"area_sq_km\" not in panel.columns:\n",
    "    if \"Area Sq Km\" in panel.columns:\n",
    "        panel[\"area_sq_km\"] = panel[\"Area Sq Km\"]\n",
    "    else:\n",
    "        raise ValueError(\"Can't find the area\")\n",
    "\n",
    "panel[\"pop_density\"] = panel[\"population\"] / panel[\"area_sq_km\"]\n",
    "panel.loc[~np.isfinite(panel[\"pop_density\"]), \"pop_density\"] = np.nan\n",
    "\n",
    "# Treat vs Control\n",
    "panel[\"treat\"]   = (panel[DIST_COL] <= T1).astype(int)\n",
    "panel[\"control\"] = (panel[DIST_COL] >= T2).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "def cohort_size_table(df):\n",
    "    \"\"\"Statistics by announcement year: Number of \"deduplicated\" LSOA in the treatment group.\"\"\"\n",
    "    tmp = df.loc[df[\"treat\"]==1, [ID_COL, COHORT_COL]].drop_duplicates()\n",
    "    tab = tmp.groupby(COHORT_COL)[ID_COL].nunique().reset_index()\n",
    "    tab.columns = [\"cohort\", \"treated_LSOA\"]\n",
    "    tab = tab.sort_values(\"cohort\")\n",
    "    return tab\n",
    "\n",
    "def plot_cohort_size(tab, cutoff=50, title=\"Cohort Treated LSOA Size\"):\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.bar(tab[\"cohort\"], tab[\"treated_LSOA\"], color=\"skyblue\")\n",
    "    plt.axhline(cutoff, color=\"red\", linestyle=\"--\", label=f\"threshold={cutoff}\")\n",
    "    plt.xlabel(\"Announcement year (cohort)\")\n",
    "    plt.ylabel(\"Treated LSOA (unique)\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def build_cohort_panel(df, cohort, window=8):\n",
    "    \n",
    "    sub = df[df[COHORT_COL] == cohort].copy()\n",
    "    if sub.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    sub = sub[(sub[\"treat\"]==1) | (sub[\"control\"]==1)].copy()\n",
    "\n",
    "    event_ts = pd.Timestamp(f\"{int(cohort)}-03-01\")\n",
    "    sub[\"event_time\"] = event_ts\n",
    "\n",
    "    # Relative quarterly window\n",
    "    sub[\"date_q\"]  = pd.PeriodIndex(sub[DATE_COL], freq=\"Q\")\n",
    "    sub[\"event_q\"] = pd.PeriodIndex(sub[\"event_time\"], freq=\"Q\")\n",
    "    sub[\"k\"] = sub[\"date_q\"].astype(int) - sub[\"event_q\"].astype(int)\n",
    "    sub = sub[(sub[\"k\"]>=-window) & (sub[\"k\"]<=window)].copy()\n",
    "\n",
    "    # log median price\n",
    "    sub = sub[sub[\"median_price\"]>0].copy()\n",
    "    sub[\"log_price\"] = np.log(sub[\"median_price\"])\n",
    "\n",
    "    return sub\n",
    "\n",
    "def stacked_event_study(df, window=8, cohorts_filter=None, plot_title_suffix=\"\", do_wald=True):\n",
    "    # 1) Select the cohort collection\n",
    "    cohorts_all = sorted(df[COHORT_COL].dropna().unique())\n",
    "    if cohorts_filter is not None:\n",
    "        allow = set(int(c) for c in cohorts_filter)\n",
    "        cohorts = [int(c) for c in cohorts_all if int(c) in allow]\n",
    "    else:\n",
    "        cohorts = [int(c) for c in cohorts_all]\n",
    "\n",
    "    # 2) Subsamples are constructed cohort by cohort and stacked\n",
    "    pieces = []\n",
    "    for c in cohorts:\n",
    "        sub = build_cohort_panel(df, c, window=window)\n",
    "        if not sub.empty:\n",
    "            pieces.append(sub)\n",
    "    if not pieces:\n",
    "        print(\"There is no stackable cohort sample.\")\n",
    "        return None, None, None\n",
    "\n",
    "    stacked = pd.concat(pieces, ignore_index=True)\n",
    "\n",
    "    # 3) Event period dummy (treatment group only)\n",
    "    k_min, k_max = -window, window\n",
    "    for kk in range(k_min, k_max + 1):\n",
    "        if kk == -1:\n",
    "            continue\n",
    "        col = f\"ev_{kk}\"\n",
    "        stacked[col] = ((stacked[\"k\"] == kk) & (stacked[\"treat\"] == 1)).astype(int)\n",
    "\n",
    "    ev_cols = [f\"ev_{kk}\" for kk in range(k_min, k_max + 1) if kk != -1]\n",
    "\n",
    "    # 4) Set up two levels of indexes, and then take Y/X and go to PanelOLS\n",
    "    stacked = stacked.set_index([ID_COL, DATE_COL]).sort_index()\n",
    "\n",
    "    # Control variables: Only those that exist and are nonconstant are kept\n",
    "    use_ctrls = [c for c in BASE_CTRLS if (c in stacked.columns) and (stacked[c].nunique(dropna=True) > 1)]\n",
    "    use_exog_cols = [c for c in ev_cols if c in stacked.columns] + use_ctrls\n",
    "    if not use_exog_cols:\n",
    "        print(\" No independent variables available (event terms may be fully absorbed).\")\n",
    "        return None, None, None\n",
    "\n",
    "    Y = stacked[\"log_price\"]\n",
    "    X = stacked[use_exog_cols]\n",
    "\n",
    "    # 5) Panel regression\n",
    "    mod = PanelOLS(Y, X, entity_effects=True, time_effects=True, drop_absorbed=True)\n",
    "    res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "\n",
    "    # 6) Wald Test（k ≤ -2）\n",
    "    wald = None\n",
    "    if do_wald:\n",
    "            actual_ev = [v for v in ev_cols if v in res.params.index]\n",
    "            pre_vars = [v for v in actual_ev if int(v.split(\"_\")[1]) <= -2]\n",
    "    if pre_vars:\n",
    "            try:\n",
    "                import numpy as np\n",
    "                idx = res.params.index\n",
    "                # Each parameter to be tested corresponds to a row of unit vectors\n",
    "                R = np.vstack([np.eye(len(idx))[idx.get_loc(v)] for v in pre_vars])\n",
    "                q = np.zeros(len(pre_vars))\n",
    "                wald = res.wald_test(R, q)\n",
    "                print(f\"[Wald] Parrallel：chi2={wald.stat:.2f}, p={wald.pval:.3g}\")\n",
    "            except Exception as e:\n",
    "                print(f\" Wald failed：{e}\")\n",
    "    else:\n",
    "            print(\" There are no prior coefficients available for parallel trend testing.\")\n",
    "\n",
    "\n",
    "    # 7) Plot\n",
    "    actual_ev = [v for v in ev_cols if v in res.params.index]\n",
    "    if not actual_ev:\n",
    "        print(\" The event period coefficients are all absorbed and cannot be plotted.\")\n",
    "        return res, wald, None\n",
    "\n",
    "    betas = res.params.loc[actual_ev]\n",
    "    ci_df = res.conf_int().loc[actual_ev]\n",
    "    \n",
    "    if \"lower\" in ci_df.columns:\n",
    "        lower, upper = ci_df[\"lower\"].values, ci_df[\"upper\"].values\n",
    "    else:\n",
    "        lower, upper = ci_df.iloc[:, 0].values, ci_df.iloc[:, 1].values\n",
    "\n",
    "    ks = np.array([int(v.split(\"_\")[1]) for v in actual_ev])\n",
    "    order = np.argsort(ks)\n",
    "    x, y = ks[order], betas.values[order]\n",
    "    l, u = lower[order], upper[order]\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 5.2))\n",
    "    plt.plot(x, y, marker=\"o\", label=\"Estimate\")\n",
    "    plt.fill_between(x, l, u, alpha=0.25, label=\"95% CI\")\n",
    "    plt.axhline(0, color=\"black\", lw=1)\n",
    "    plt.axvline(0, color=\"red\", ls=\"--\", label=\"Event (k=0)\")\n",
    "    ttl = \"Stacked Event Study\"\n",
    "    if plot_title_suffix:\n",
    "        ttl += f\" — {plot_title_suffix}\"\n",
    "    plt.title(ttl)\n",
    "    plt.xlabel(\"Quarters relative to announcement\")\n",
    "    plt.ylabel(\"Effect on log(price)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return res, wald, fig\n",
    "\n",
    "\n",
    "# 1) Cohort Sample size (deduplicating LSOA)\n",
    "tab_full = cohort_size_table(panel)\n",
    "print(\"Cohort sizes (Full sample):\\n\", tab_full)\n",
    "\n",
    "# Plot distribution\n",
    "plot_cohort_size(tab_full, cutoff=50, title=\"Cohort Treated LSOA Size — Full sample\")\n",
    "\n",
    "\n",
    "# 2) Main result: full coverage, window ±8\n",
    "res_full, wald_full, _ = stacked_event_study(\n",
    "    panel, window=8, cohorts_filter=None, plot_title_suffix=\"All cohorts (no filter)\", do_wald=True\n",
    ")\n",
    "\n",
    "\n",
    "# 3) Robustness A: screening (each cohort handles LSOA ≥ 50) with a window of ±8\n",
    "\n",
    "allowed = set(tab_full.loc[tab_full[\"treated_LSOA\"]>=50, \"cohort\"])\n",
    "tab_flt = tab_full[tab_full[\"cohort\"].isin(allowed)].copy()\n",
    "print(\"Cohort sizes (Filtered):\\n\", tab_flt)\n",
    "\n",
    "\n",
    "plot_cohort_size(tab_flt, cutoff=50, title=\"Cohort Treated LSOA Size — Filtered (≥50)\")\n",
    "\n",
    "res_flt, wald_flt, _ = stacked_event_study(\n",
    "    panel, window=8, cohorts_filter=allowed, plot_title_suffix=\"Cohort treated≥50\", do_wald=True\n",
    ")\n",
    "\n",
    "# Overlay main results vs filter results \n",
    "def overlay_two_curves(resA, labelA, resB, labelB, title=\"Robustness: cohort size filter\"):\n",
    "    def extract_xy(rr):\n",
    "        evs = [v for v in rr.params.index if v.startswith(\"ev_\")]\n",
    "        ks = np.array([int(v.split(\"_\")[1]) for v in evs])\n",
    "        order = np.argsort(ks)\n",
    "        y = rr.params.loc[evs].values[order]\n",
    "        ci = rr.conf_int().loc[evs]\n",
    "        if \"lower\" in ci.columns:\n",
    "            l, u = ci[\"lower\"].values[order], ci[\"upper\"].values[order]\n",
    "        else:\n",
    "            l, u = ci.iloc[:,0].values[order], ci.iloc[:,1].values[order]\n",
    "        return ks[order], y, l, u\n",
    "\n",
    "    x1, y1, l1, u1 = extract_xy(resA)\n",
    "    x2, y2, l2, u2 = extract_xy(resB)\n",
    "\n",
    "    plt.figure(figsize=(8,5.2))\n",
    "    plt.plot(x1, y1, marker=\"o\", label=labelA, alpha=0.9)\n",
    "    plt.fill_between(x1, l1, u1, alpha=0.15)\n",
    "    plt.plot(x2, y2, marker=\"s\", label=labelB, alpha=0.9)\n",
    "    plt.fill_between(x2, l2, u2, alpha=0.15)\n",
    "    plt.axhline(0, color=\"black\", lw=1)\n",
    "    plt.axvline(0, color=\"red\", ls=\"--\", label=\"Event (k=0)\")\n",
    "    plt.xlabel(\"Quarters relative to announcement\")\n",
    "    plt.ylabel(\"Effect on log(price)\")\n",
    "    plt.title(f\"Stacked Event Study — {title}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "overlay_two_curves(res_full,  \"Full sample\",\n",
    "                   res_flt,   \"Filtered (treated≥50)\",\n",
    "                   title=\"Robustness: Cohort size filter\")\n",
    "\n",
    "\n",
    "# 4) Robustness B: expanded window ±12 (full sample)\n",
    "\n",
    "res_full_w12, wald_full_w12, _ = stacked_event_study(\n",
    "    panel, window=12, cohorts_filter=None, plot_title_suffix=\"All cohorts, window ±12\", do_wald=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a2b7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DIST_COL   = \"d_net_min_km\"    \n",
    "ID_COL     = \"lsoa21cd\"\n",
    "DATE_COL   = \"date\"\n",
    "COHORT_COL = \"announcement_year\"\n",
    "T1, T2     = 1.0, 2.0\n",
    "BASE_CTRLS = [\"share_detached\",\"share_semi_detached\",\"share_terraced\",\n",
    "              \"share_flat\",\"total_sales\",\"pop_density\"]\n",
    "\n",
    "\n",
    "panel = pd.read_csv(\"output/Final_panel_data.csv\", dtype={ID_COL: str})\n",
    "panel[DATE_COL] = pd.to_datetime(panel[DATE_COL])\n",
    "\n",
    "\n",
    "if \"area_sq_km\" not in panel.columns and \"Area Sq Km\" in panel.columns:\n",
    "    panel[\"area_sq_km\"] = panel[\"Area Sq Km\"]\n",
    "panel[\"pop_density\"] = panel[\"population\"] / panel[\"area_sq_km\"]\n",
    "panel.loc[~np.isfinite(panel[\"pop_density\"]), \"pop_density\"] = np.nan\n",
    "\n",
    "panel[\"treat\"] = (panel[DIST_COL] <= T1).astype(int)\n",
    "\n",
    "# A) Control = same cohort and ≥T2\n",
    "def build_cohort_panel_outer(df, cohort, window=8):\n",
    "    sub = df[df[COHORT_COL] == cohort].copy()\n",
    "    if sub.empty:\n",
    "        return pd.DataFrame()\n",
    "    # Control = same cohort and ≥T2; The treatment =≤T1\n",
    "    sub[\"control_outer\"] = (sub[DIST_COL] >= T2).astype(int)\n",
    "    sub = sub[(sub[\"treat\"]==1) | (sub[\"control_outer\"]==1)].copy()\n",
    "\n",
    "    event_ts = pd.Timestamp(f\"{int(cohort)}-03-01\")\n",
    "    sub[\"event_time\"] = event_ts\n",
    "    sub[\"date_q\"]  = pd.PeriodIndex(sub[DATE_COL], freq=\"Q\")\n",
    "    sub[\"event_q\"] = pd.PeriodIndex(sub[\"event_time\"], freq=\"Q\")\n",
    "    sub[\"k\"] = sub[\"date_q\"].astype(int) - sub[\"event_q\"].astype(int)\n",
    "    sub = sub[(sub[\"k\"]>=-window) & (sub[\"k\"]<=window)]\n",
    "    sub = sub[sub[\"median_price\"]>0].copy()\n",
    "    sub[\"log_price\"] = np.log(sub[\"median_price\"])\n",
    "    return sub\n",
    "\n",
    "def run_stacked_es_outer(df, window=8):\n",
    "    cohorts = sorted(df[COHORT_COL].dropna().astype(int).unique())\n",
    "    pieces = []\n",
    "    for c in cohorts:\n",
    "        sub = build_cohort_panel_outer(df, c, window)\n",
    "        if not sub.empty and sub[\"treat\"].sum()>0 and sub[\"control_outer\"].sum()>0:\n",
    "            pieces.append(sub)\n",
    "    stacked = pd.concat(pieces, ignore_index=True)\n",
    "\n",
    "    # Events are virtual (only groups are processed), omitting k=-1\n",
    "    k_min, k_max = -window, window\n",
    "    for kk in range(k_min, k_max+1):\n",
    "        if kk == -1: \n",
    "            continue\n",
    "        col = f\"ev_{kk}\"\n",
    "        stacked[col] = ((stacked[\"k\"]==kk) & (stacked[\"treat\"]==1)).astype(int)\n",
    "\n",
    "    ev_cols = [f\"ev_{kk}\" for kk in range(k_min, k_max+1) if kk != -1]\n",
    "    stacked = stacked.set_index([ID_COL, DATE_COL]).sort_index()\n",
    "    use_ctrls = [c for c in BASE_CTRLS if c in stacked.columns and stacked[c].nunique(dropna=True)>1]\n",
    "    Y = stacked[\"log_price\"]; X = stacked[ev_cols + use_ctrls]\n",
    "\n",
    "    mod = PanelOLS(Y, X, entity_effects=True, time_effects=True, drop_absorbed=True)\n",
    "    res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "\n",
    "    # Extracting a plot array\n",
    "    ev_keep = [c for c in ev_cols if c in res.params.index]\n",
    "    ks = np.array([int(v.split(\"_\")[1]) for v in ev_keep]); order = np.argsort(ks)\n",
    "    beta = res.params.loc[ev_keep].values[order]\n",
    "    ci = res.conf_int().loc[ev_keep]\n",
    "    lo = (ci[\"lower\"] if \"lower\" in ci.columns else ci.iloc[:,0]).values[order]\n",
    "    hi = (ci[\"upper\"] if \"upper\" in ci.columns else ci.iloc[:,1]).values[order]\n",
    "    return ks[order], beta, lo, hi, res\n",
    "\n",
    "# B) Ring-control control=same cohort and T1<dist<T2）\n",
    "def build_cohort_panel_ring(df, cohort, window=8, t1=T1, t2=T2):\n",
    "    sub = df[df[COHORT_COL] == cohort].copy()\n",
    "    if sub.empty:\n",
    "        return pd.DataFrame()\n",
    "    # \"ring\"：T1 < dist < T2\n",
    "    sub[\"control_ring\"] = ((sub[DIST_COL] > t1) & (sub[DIST_COL] < t2)).astype(int)\n",
    "    sub = sub[(sub[\"treat\"]==1) | (sub[\"control_ring\"]==1)].copy()\n",
    "\n",
    "    event_ts = pd.Timestamp(f\"{int(cohort)}-03-01\")\n",
    "    sub[\"event_time\"] = event_ts\n",
    "    sub[\"date_q\"]  = pd.PeriodIndex(sub[DATE_COL], freq=\"Q\")\n",
    "    sub[\"event_q\"] = pd.PeriodIndex(sub[\"event_time\"], freq=\"Q\")\n",
    "    sub[\"k\"] = sub[\"date_q\"].astype(int) - sub[\"event_q\"].astype(int)\n",
    "    sub = sub[(sub[\"k\"]>=-window) & (sub[\"k\"]<=window)]\n",
    "    sub = sub[sub[\"median_price\"]>0].copy()\n",
    "    sub[\"log_price\"] = np.log(sub[\"median_price\"])\n",
    "    return sub\n",
    "\n",
    "def run_stacked_es_ring(df, window=8, t1=T1, t2=T2):\n",
    "    cohorts = sorted(df[COHORT_COL].dropna().astype(int).unique())\n",
    "    pieces = []\n",
    "    for c in cohorts:\n",
    "        sub = build_cohort_panel_ring(df, c, window, t1, t2)\n",
    "        \n",
    "        if not sub.empty and sub[\"treat\"].sum()>0 and sub[\"control_ring\"].sum()>0:\n",
    "            pieces.append(sub)\n",
    "    stacked = pd.concat(pieces, ignore_index=True)\n",
    "\n",
    "   \n",
    "    k_min, k_max = -window, window\n",
    "    for kk in range(k_min, k_max+1):\n",
    "        if kk == -1:\n",
    "            continue\n",
    "        col = f\"ev_{kk}\"\n",
    "        stacked[col] = ((stacked[\"k\"]==kk) & (stacked[\"treat\"]==1)).astype(int)\n",
    "\n",
    "    ev_cols = [f\"ev_{kk}\" for kk in range(k_min, k_max+1) if kk != -1]\n",
    "    stacked = stacked.set_index([ID_COL, DATE_COL]).sort_index()\n",
    "    use_ctrls = [c for c in BASE_CTRLS if c in stacked.columns and stacked[c].nunique(dropna=True)>1]\n",
    "    Y = stacked[\"log_price\"]; X = stacked[ev_cols + use_ctrls]\n",
    "\n",
    "    mod = PanelOLS(Y, X, entity_effects=True, time_effects=True, drop_absorbed=True)\n",
    "    res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "\n",
    "    \n",
    "    ev_keep = [c for c in ev_cols if c in res.params.index]\n",
    "    ks = np.array([int(v.split(\"_\")[1]) for v in ev_keep]); order = np.argsort(ks)\n",
    "    beta = res.params.loc[ev_keep].values[order]\n",
    "    ci = res.conf_int().loc[ev_keep]\n",
    "    lo = (ci[\"lower\"] if \"lower\" in ci.columns else ci.iloc[:,0]).values[order]\n",
    "    hi = (ci[\"upper\"] if \"upper\" in ci.columns else ci.iloc[:,1]).values[order]\n",
    "    return ks[order], beta, lo, hi, res, stacked\n",
    "\n",
    "# C) Wald Test\n",
    "def wald_pretrend(res, ev_prefix=\"ev_\", pre_max=-2):\n",
    "    idx = res.params.index\n",
    "    ev_vars = [v for v in idx if v.startswith(ev_prefix)]\n",
    "    pre_vars = [v for v in ev_vars if int(v.split(\"_\")[1]) <= pre_max]\n",
    "    if not pre_vars:\n",
    "        print(\"There are no prior coefficients available for parallel trend testing.\")\n",
    "        return None\n",
    "    R = np.vstack([np.eye(len(idx))[idx.get_loc(v)] for v in pre_vars])\n",
    "    q = np.zeros(len(pre_vars))\n",
    "    w = res.wald_test(R, q)\n",
    "    print(f\"[Wald pretrend] chi2={w.stat:.2f}, p={w.pval:.3g}  (H0: all pre-k<=-2 = 0)\")\n",
    "    return w\n",
    "\n",
    "\n",
    "# Run and Plot\n",
    "ks_out, b_out, l_out, u_out, res_out = run_stacked_es_outer(panel, window=8)\n",
    "ks_ring, b_ring, l_ring, u_ring, res_ring, data_ring = run_stacked_es_ring(panel, window=8, t1=T1, t2=T2)\n",
    "\n",
    "wald_pretrend(res_out)\n",
    "wald_pretrend(res_ring)\n",
    "\n",
    "# Align the vertical axis range\n",
    "ymin = min(l_out.min(), l_ring.min()) - 0.01\n",
    "ymax = max(u_out.max(), u_ring.max()) + 0.01\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13,5), sharey=True)\n",
    "\n",
    "# Left: Baseline (outer circle ≥T2 is the control)\n",
    "ax = axes[0]\n",
    "ax.plot(ks_out, b_out, marker=\"o\", label=\"Estimate\")\n",
    "ax.fill_between(ks_out, l_out, u_out, alpha=0.25, label=\"95% CI\")\n",
    "ax.axhline(0, color=\"black\", lw=1)\n",
    "ax.axvline(0, color=\"red\", ls=\"--\", label=\"Event (k=0)\")\n",
    "ax.set_title(\"Baseline — Control: same cohort, dist ≥ T2\")\n",
    "ax.set_xlabel(\"Quarters relative to announcement\")\n",
    "ax.set_ylabel(\"Effect on log(price)\")\n",
    "ax.set_ylim(ymin, ymax)\n",
    "ax.legend()\n",
    "\n",
    "# Right：Ring-control\n",
    "ax = axes[1]\n",
    "ax.plot(ks_ring, b_ring, marker=\"o\", label=\"Estimate\")\n",
    "ax.fill_between(ks_ring, l_ring, u_ring, alpha=0.25, label=\"95% CI\")\n",
    "ax.axhline(0, color=\"black\", lw=1)\n",
    "ax.axvline(0, color=\"red\", ls=\"--\", label=\"Event (k=0)\")\n",
    "ax.set_title(\"Ring Control — Control: same cohort, T1 < dist < T2\")\n",
    "ax.set_xlabel(\"Quarters relative to announcement\")\n",
    "ax.set_ylim(ymin, ymax)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faffc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DIST_COL   = \"d_net_min_km\"\n",
    "ID_COL     = \"lsoa21cd\"\n",
    "DATE_COL   = \"date\"\n",
    "COHORT_COL = \"announcement_year\"\n",
    "T1, T2     = 1.0, 2.0\n",
    "WINDOW     = 8\n",
    "POST_RANGE = range(0, WINDOW+1)   \n",
    "BASE_CTRLS = [\"share_detached\",\"share_semi_detached\",\"share_terraced\",\n",
    "              \"share_flat\",\"total_sales\",\"pop_density\"]\n",
    "\n",
    "# Read and preprocessing\n",
    "panel = pd.read_csv(\"output/Final_panel_data.csv\", dtype={ID_COL: str})\n",
    "panel[DATE_COL] = pd.to_datetime(panel[DATE_COL])\n",
    "\n",
    "if \"area_sq_km\" not in panel.columns and \"Area Sq Km\" in panel.columns:\n",
    "    panel[\"area_sq_km\"] = panel[\"Area Sq Km\"]\n",
    "panel[\"pop_density\"] = panel[\"population\"] / panel[\"area_sq_km\"]\n",
    "panel.loc[~np.isfinite(panel[\"pop_density\"]), \"pop_density\"] = np.nan\n",
    "\n",
    "panel = panel[panel[\"median_price\"]>0].copy()\n",
    "panel[\"log_price\"] = np.log(panel[\"median_price\"])\n",
    "\n",
    "# Distance grouping: near, ring, outer ring (outer ring is control)\n",
    "panel[\"near\"]  = (panel[DIST_COL] <= T1).astype(int)\n",
    "panel[\"ring\"]  = ((panel[DIST_COL] > T1) & (panel[DIST_COL] < T2)).astype(int)\n",
    "panel[\"outer\"] = (panel[DIST_COL] >= T2).astype(int)\n",
    "\n",
    "# Construct \"same cohort\" stacked samples \n",
    "def build_stacked_same_cohort(df, cohort, window=WINDOW):\n",
    "    sub = df[df[COHORT_COL]==cohort].copy()\n",
    "    if sub.empty: \n",
    "        return pd.DataFrame()\n",
    "\n",
    "    \n",
    "    sub = sub[(sub[\"near\"]==1) | (sub[\"ring\"]==1) | (sub[\"outer\"]==1)].copy()\n",
    "\n",
    "    event_ts = pd.Timestamp(f\"{int(cohort)}-03-01\")\n",
    "    sub[\"event_time\"] = event_ts\n",
    "    sub[\"date_q\"]  = pd.PeriodIndex(sub[DATE_COL], freq=\"Q\")\n",
    "    sub[\"event_q\"] = pd.PeriodIndex(sub[\"event_time\"], freq=\"Q\")\n",
    "    sub[\"k\"] = sub[\"date_q\"].astype(int) - sub[\"event_q\"].astype(int)\n",
    "    sub = sub[(sub[\"k\"]>=-window) & (sub[\"k\"]<=window)]\n",
    "    return sub\n",
    "\n",
    "cohorts = sorted(panel[COHORT_COL].dropna().astype(int).unique())\n",
    "stacked = pd.concat([build_stacked_same_cohort(panel, c, WINDOW) \n",
    "                     for c in cohorts if not build_stacked_same_cohort(panel, c, WINDOW).empty],\n",
    "                    ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# Event virtual × distance band (assigned to processing band only), omitting k=-1 base period\n",
    "k_min, k_max = -WINDOW, WINDOW\n",
    "for kk in range(k_min, k_max+1):\n",
    "    if kk == -1:\n",
    "        continue\n",
    "    # Interaction terms are created for near/ring bands respectively. \n",
    "    stacked[f\"ev_{kk}_near\"] = ((stacked[\"k\"]==kk) & (stacked[\"near\"]==1)).astype(int)\n",
    "    stacked[f\"ev_{kk}_ring\"] = ((stacked[\"k\"]==kk) & (stacked[\"ring\"]==1)).astype(int)\n",
    "\n",
    "# Regression: TWFE\n",
    "stacked = stacked.set_index([ID_COL, DATE_COL]).sort_index()\n",
    "use_ctrls = [c for c in BASE_CTRLS if c in stacked.columns and stacked[c].nunique(dropna=True)>1]\n",
    "\n",
    "ev_near = [f\"ev_{kk}_near\" for kk in range(k_min, k_max+1) if kk != -1]\n",
    "ev_ring = [f\"ev_{kk}_ring\" for kk in range(k_min, k_max+1) if kk != -1]\n",
    "X_cols  = ev_near + ev_ring + use_ctrls\n",
    "\n",
    "mod = PanelOLS(stacked[\"log_price\"], stacked[X_cols],\n",
    "               entity_effects=True, time_effects=True, drop_absorbed=True)\n",
    "res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "\n",
    "print(res.summary)\n",
    "\n",
    "# \"Mean\" the coefficients in the post-announcement window and give the 95%CI (linear combination)\n",
    "def avg_post_effect(res, name_prefix, post_ks=POST_RANGE):\n",
    "    # choose k in post_ks \n",
    "    names = [f\"ev_{k}_{name_prefix}\" for k in range(k_min, k_max+1) if (k in post_ks and k != -1)]\n",
    "    names = [n for n in names if n in res.params.index]\n",
    "    if not names:\n",
    "        return np.nan, (np.nan, np.nan)\n",
    "\n",
    "    beta = res.params.loc[names].values\n",
    "    cov  = res.cov.loc[names, names].values\n",
    "    w = np.ones(len(names)) / len(names)         # Equal weight average\n",
    "    est = float(w @ beta)\n",
    "    se  = float(np.sqrt(w @ cov @ w))\n",
    "    lo, hi = est - 1.96*se, est + 1.96*se\n",
    "    return est, (lo, hi)\n",
    "\n",
    "near_est, (near_lo, near_hi) = avg_post_effect(res, \"near\", POST_RANGE)\n",
    "ring_est, (ring_lo, ring_hi) = avg_post_effect(res, \"ring\", POST_RANGE)\n",
    "\n",
    "# Draw a distance decay curve\n",
    "xs  = np.array([0.5, 1.5])     \n",
    "ys  = np.array([near_est, ring_est])\n",
    "los = np.array([near_lo, ring_lo])\n",
    "his = np.array([near_hi, ring_hi])\n",
    "\n",
    "plt.figure(figsize=(6,4.2))\n",
    "plt.errorbar(xs, ys, yerr=[ys-los, his-ys], fmt=\"o-\", capsize=4, linewidth=2, markersize=6, label=\"Avg post (k≥0)\")\n",
    "plt.axhline(0, color=\"black\", lw=1)\n",
    "plt.xlabel(\"Distance to nearest station (km)\")\n",
    "plt.ylabel(\"Average post-announcement effect on log(price)\")\n",
    "plt.title(\"Distance Decay of Announcement Effect (vs. ≥2km control)\")\n",
    "plt.xticks(xs, [\"≤1 km (0.5)\", \"1–2 km (1.5)\"])\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def extract_path(res, prefix):\n",
    "    names = [f\"ev_{k}_{prefix}\" for k in range(k_min, k_max+1) if k != -1]\n",
    "    names = [n for n in names if n in res.params.index]\n",
    "    ks = np.array([int(n.split(\"_\")[1]) for n in names])\n",
    "    order = np.argsort(ks)\n",
    "    bet  = res.params.loc[names].values[order]\n",
    "    ci   = res.conf_int().loc[names]\n",
    "    lo   = (ci[\"lower\"] if \"lower\" in ci.columns else ci.iloc[:,0]).values[order]\n",
    "    hi   = (ci[\"upper\"] if \"upper\" in ci.columns else ci.iloc[:,1]).values[order]\n",
    "    return ks[order], bet, lo, hi\n",
    "\n",
    "ksN, bN, lN, uN = extract_path(res, \"near\")\n",
    "ksR, bR, lR, uR = extract_path(res, \"ring\")\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(12,4.2), sharey=True)\n",
    "for ax, ks, b, l, u, ttl in [(axes[0], ksN, bN, lN, uN, \"Near ≤1km\"),\n",
    "                             (axes[1], ksR, bR, lR, uR, \"Ring 1–2km\")]:\n",
    "    ax.plot(ks, b, marker=\"o\", label=\"Estimate\")\n",
    "    ax.fill_between(ks, l, u, alpha=0.25, label=\"95% CI\")\n",
    "    ax.axhline(0, color=\"black\", lw=1)\n",
    "    ax.axvline(0, color=\"red\", ls=\"--\", label=\"Event (k=0)\")\n",
    "    ax.set_title(ttl); ax.set_xlabel(\"Quarters relative to announcement\")\n",
    "axes[0].set_ylabel(\"Effect on log(price)\")\n",
    "axes[0].legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2c41c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIST_COL   = \"d_net_min_km\"     \n",
    "ID_COL     = \"lsoa21cd\"\n",
    "DATE_COL   = \"date\"\n",
    "COHORT_COL = \"announcement_year\"\n",
    "\n",
    "WINDOW     = 8                 \n",
    "CTRL_MIN   = 2.0               \n",
    "BANDS = [(0.0,0.5), (0.5,1.0), (1.0,1.5), (1.5,2.0)]\n",
    "BASE_CTRLS = [\"share_detached\",\"share_semi_detached\",\"share_terraced\",\n",
    "              \"share_flat\",\"total_sales\",\"pop_density\"]\n",
    "\n",
    "# Read and preprocessing\n",
    "panel = pd.read_csv(\"data/Final_panel_data3.csv\", dtype={ID_COL: str})\n",
    "panel[DATE_COL] = pd.to_datetime(panel[DATE_COL])\n",
    "\n",
    "if \"area_sq_km\" not in panel.columns and \"Area Sq Km\" in panel.columns:\n",
    "    panel[\"area_sq_km\"] = panel[\"Area Sq Km\"]\n",
    "panel[\"pop_density\"] = panel[\"population\"] / panel[\"area_sq_km\"]\n",
    "panel.loc[~np.isfinite(panel[\"pop_density\"]), \"pop_density\"] = np.nan\n",
    "\n",
    "panel = panel[panel[\"median_price\"]>0].copy()\n",
    "panel[\"log_price\"] = np.log(panel[\"median_price\"])\n",
    "panel[\"dist_km\"] = panel[DIST_COL]\n",
    "\n",
    "# Constructing band label\n",
    "def band_label(lo, hi):\n",
    "    # (lo, hi]\n",
    "    if lo == 0.0:\n",
    "        return f\"≤{hi:.1f}\"\n",
    "    return f\"{lo:.1f}–{hi:.1f}\"\n",
    "\n",
    "def in_band(d, lo, hi):\n",
    "    # (lo, hi] rule, 0 belongs to the first bracket\n",
    "    if lo == 0.0:\n",
    "        return (d <= hi)\n",
    "    return (d > lo) & (d <= hi)\n",
    "\n",
    "for (lo, hi) in BANDS:\n",
    "    col = f\"band_{lo}_{hi}\"\n",
    "    panel[col] = in_band(panel[\"dist_km\"], lo, hi).astype(int)\n",
    "\n",
    "panel[\"outer2\"] = (panel[\"dist_km\"] > CTRL_MIN).astype(int) \n",
    "\n",
    "# Stacking samples from the same cohort\n",
    "def build_stacked(df, cohort, window=WINDOW):\n",
    "    sub = df[df[COHORT_COL]==cohort].copy()\n",
    "    if sub.empty:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    keep_mask = sub[\"outer2\"]==1\n",
    "    for (lo,hi) in BANDS:\n",
    "        keep_mask |= (sub[f\"band_{lo}_{hi}\"]==1)\n",
    "    sub = sub[keep_mask].copy()\n",
    "\n",
    "    sub[\"event_time\"] = pd.Timestamp(f\"{int(cohort)}-03-01\")\n",
    "    sub[\"date_q\"]  = pd.PeriodIndex(sub[DATE_COL], freq=\"Q\")\n",
    "    sub[\"event_q\"] = pd.PeriodIndex(sub[\"event_time\"], freq=\"Q\")\n",
    "    sub[\"k\"] = sub[\"date_q\"].astype(int) - sub[\"event_q\"].astype(int)\n",
    "    sub = sub[(sub[\"k\"]>=-window) & (sub[\"k\"]<=window)]\n",
    "    return sub\n",
    "\n",
    "cohorts = sorted(panel[COHORT_COL].dropna().astype(int).unique())\n",
    "pieces = []\n",
    "for c in cohorts:\n",
    "    sub = build_stacked(panel, c, WINDOW)\n",
    "    if not sub.empty:\n",
    "        \n",
    "        if (sub[\"outer2\"].sum()>0) and any(sub[f\"band_{lo}_{hi}\"].sum()>0 for (lo,hi) in BANDS):\n",
    "            pieces.append(sub)\n",
    "stacked = pd.concat(pieces, ignore_index=True)\n",
    "\n",
    "# Event virtual × each band (omitting k=-1)\n",
    "k_min, k_max = -WINDOW, WINDOW\n",
    "for (lo,hi) in BANDS:\n",
    "    for kk in range(k_min, k_max+1):\n",
    "        if kk == -1:\n",
    "            continue\n",
    "        col = f\"ev_{kk}_b{lo}_{hi}\"\n",
    "        bandcol = f\"band_{lo}_{hi}\"\n",
    "        stacked[col] = ((stacked[\"k\"]==kk) & (stacked[bandcol]==1)).astype(int)\n",
    "\n",
    "# Regression TWFE\n",
    "df_idx = stacked.set_index([ID_COL, DATE_COL]).sort_index()\n",
    "use_ctrls = [c for c in BASE_CTRLS if c in df_idx.columns and df_idx[c].nunique(dropna=True)>1]\n",
    "\n",
    "ev_cols = []\n",
    "for (lo,hi) in BANDS:\n",
    "    ev_cols += [f\"ev_{kk}_b{lo}_{hi}\" for kk in range(k_min, k_max+1) if kk != -1]\n",
    "\n",
    "X = df_idx[ev_cols + use_ctrls].copy()\n",
    "Y = df_idx[\"log_price\"]\n",
    "\n",
    "# Constant/all-zero columns are automatically dropped to avoid rank deficiency\n",
    "keep_cols = [c for c in X.columns if X[c].std(skipna=True) > 0]\n",
    "X = X[keep_cols]\n",
    "\n",
    "mod = PanelOLS(Y, X, entity_effects=True, time_effects=True, drop_absorbed=True)\n",
    "res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "print(res.summary)\n",
    "\n",
    "# Extract Path, mean and CI, Wald pretrend \n",
    "def extract_path(res, lo, hi):\n",
    "    names = [f\"ev_{k}_b{lo}_{hi}\" for k in range(k_min, k_max+1) if k != -1]\n",
    "    names = [n for n in names if n in res.params.index]\n",
    "    ks = np.array([int(n.split(\"_\")[1]) for n in names])\n",
    "    order = np.argsort(ks)\n",
    "    bet  = res.params.loc[names].values[order]\n",
    "    ci   = res.conf_int().loc[names]\n",
    "    low  = (ci[\"lower\"] if \"lower\" in ci.columns else ci.iloc[:,0]).values[order]\n",
    "    high = (ci[\"upper\"] if \"upper\" in ci.columns else ci.iloc[:,1]).values[order]\n",
    "    return ks[order], bet, low, high\n",
    "\n",
    "def avg_post(res, lo, hi, post_range=range(0, WINDOW+1)):\n",
    "    names = [f\"ev_{k}_b{lo}_{hi}\" for k in post_range if k != -1]\n",
    "    names = [n for n in names if n in res.params.index]\n",
    "    if not names:\n",
    "        return np.nan, (np.nan, np.nan)\n",
    "    beta = res.params.loc[names].values\n",
    "    cov  = res.cov.loc[names, names].values\n",
    "    w = np.ones(len(names))/len(names)\n",
    "    est = float(w @ beta)\n",
    "    se  = float(np.sqrt(w @ cov @ w))\n",
    "    lo95, hi95 = est - 1.96*se, est + 1.96*se\n",
    "    return est, (lo95, hi95)\n",
    "\n",
    "def wald_pretrend_by_band(res, lo, hi, pre_max=-2):\n",
    "    idx = res.params.index\n",
    "    vars_ = [f\"ev_{k}_b{lo}_{hi}\" for k in range(k_min, pre_max+1)]\n",
    "    vars_ = [v for v in vars_ if v in idx]\n",
    "    if not vars_:\n",
    "        print(f\"Band({lo}-{hi}): no pretrend terms.\")\n",
    "        return None\n",
    "    R = np.vstack([np.eye(len(idx))[idx.get_loc(v)] for v in vars_])\n",
    "    q = np.zeros(len(vars_))\n",
    "    w = res.wald_test(R, q)\n",
    "    print(f\"[Pretrend] Band({lo}-{hi}) chi2={w.stat:.2f}, p={w.pval:.4f}\")\n",
    "    return w\n",
    "\n",
    "# Figure 1: Distance decay curve \n",
    "midpoints, ests, los, his = [], [], [], []\n",
    "for (lo,hi) in BANDS:\n",
    "    est, (lo95, hi95) = avg_post(res, lo, hi, post_range=range(0, WINDOW+1))\n",
    "    mid = (lo+hi)/2.0 if lo>0 else hi/2.0\n",
    "    midpoints.append(mid); ests.append(est); los.append(lo95); his.append(hi95)\n",
    "\n",
    "midpoints = np.array(midpoints); order = np.argsort(midpoints)\n",
    "midpoints, ests, los, his = midpoints[order], np.array(ests)[order], np.array(los)[order], np.array(his)[order]\n",
    "\n",
    "plt.figure(figsize=(6,4.2))\n",
    "plt.errorbar(midpoints, ests, yerr=[ests-los, his-ests], fmt=\"o-\", capsize=4, linewidth=2, markersize=6, label=\"Avg post (k≥0)\")\n",
    "plt.axhline(0, color=\"black\", lw=1)\n",
    "plt.xlabel(\"Distance to nearest station (km)\")\n",
    "plt.ylabel(\"Average post-announcement effect on log(price)\\n(vs. >2 km control)\")\n",
    "plt.title(\"Distance Decay — 0.5 km Bands\")\n",
    "plt.xticks(midpoints, [band_label(lo,hi) for (lo,hi) in np.array(BANDS)[order]])\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# Figure 2: Event study plots for each band\n",
    "n = len(BANDS)\n",
    "fig, axes = plt.subplots(1, n, figsize=(4.2*n, 4.0), sharey=True)\n",
    "if n == 1:\n",
    "    axes = [axes]\n",
    "for ax, (lo,hi) in zip(axes, BANDS):\n",
    "    ks, b, l, u = extract_path(res, lo, hi)\n",
    "    ax.plot(ks, b, marker=\"o\", label=\"Estimate\")\n",
    "    ax.fill_between(ks, l, u, alpha=0.25, label=\"95% CI\")\n",
    "    ax.axhline(0, color=\"black\", lw=1)\n",
    "    ax.axvline(0, color=\"red\", ls=\"--\", label=\"Event (k=0)\")\n",
    "    ax.set_title(f\"{band_label(lo,hi)} km\")\n",
    "    ax.set_xlabel(\"Quarters relative to announcement\")\n",
    "axes[0].set_ylabel(\"Effect on log(price)\")\n",
    "axes[0].legend()\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Pretrend Wald \n",
    "for (lo,hi) in BANDS:\n",
    "    wald_pretrend_by_band(res, lo, hi, pre_max=-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4e9f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIST_COL   = \"d_net_min_km\"   \n",
    "ID_COL     = \"lsoa21cd\"\n",
    "DATE_COL   = \"date\"\n",
    "COHORT_COL = \"announcement_year\"\n",
    "\n",
    "T_NEAR_MAX = 2.0             \n",
    "CONTROL_MIN = 2.0            \n",
    "WINDOW     = 8               \n",
    "BASE_CTRLS = [\"share_detached\",\"share_semi_detached\",\"share_terraced\",\n",
    "              \"share_flat\",\"total_sales\",\"pop_density\"]\n",
    "\n",
    "# Read an preprocessing\n",
    "panel = pd.read_csv(\"data/Final_panel_data3.csv\", dtype={ID_COL: str})\n",
    "panel[DATE_COL] = pd.to_datetime(panel[DATE_COL])\n",
    "\n",
    "if \"area_sq_km\" not in panel.columns and \"Area Sq Km\" in panel.columns:\n",
    "    panel[\"area_sq_km\"] = panel[\"Area Sq Km\"]\n",
    "panel[\"pop_density\"] = panel[\"population\"] / panel[\"area_sq_km\"]\n",
    "panel.loc[~np.isfinite(panel[\"pop_density\"]), \"pop_density\"] = np.nan\n",
    "\n",
    "panel = panel[panel[\"median_price\"]>0].copy()\n",
    "panel[\"log_price\"] = np.log(panel[\"median_price\"])\n",
    "\n",
    "# Distance and Grouping\n",
    "panel[\"dist_km\"]   = panel[DIST_COL]\n",
    "panel[\"near2\"]     = (panel[\"dist_km\"] <= T_NEAR_MAX).astype(int)       # Continuous intensities are meaningful only for ≤2km\n",
    "panel[\"outer2\"]    = (panel[\"dist_km\"] > CONTROL_MIN).astype(int)       \n",
    "panel[\"dist_in2\"]  = np.clip(panel[\"dist_km\"], 0, T_NEAR_MAX)           # The distance within [0,2]\n",
    "panel[\"dist_in2_c\"] = panel[\"dist_in2\"]                                 \n",
    "\n",
    "# Stacking the same-cohort samples\n",
    "def build_stacked(df, cohort, window=WINDOW):\n",
    "    sub = df[df[COHORT_COL]==cohort].copy()\n",
    "    if sub.empty: \n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    sub = sub[(sub[\"near2\"]==1) | (sub[\"outer2\"]==1)].copy()\n",
    "    sub[\"event_time\"] = pd.Timestamp(f\"{int(cohort)}-03-01\")\n",
    "    sub[\"date_q\"]  = pd.PeriodIndex(sub[DATE_COL], freq=\"Q\")\n",
    "    sub[\"event_q\"] = pd.PeriodIndex(sub[\"event_time\"], freq=\"Q\")\n",
    "    sub[\"k\"] = sub[\"date_q\"].astype(int) - sub[\"event_q\"].astype(int)\n",
    "    sub = sub[(sub[\"k\"]>=-window) & (sub[\"k\"]<=window)]\n",
    "    return sub\n",
    "\n",
    "cohorts = sorted(panel[COHORT_COL].dropna().astype(int).unique())\n",
    "stacked = pd.concat([build_stacked(panel, c, WINDOW) \n",
    "                     for c in cohorts if not build_stacked(panel, c, WINDOW).empty],\n",
    "                    ignore_index=True)\n",
    "\n",
    "# Instructions after announcement\n",
    "stacked[\"post\"] = (stacked[\"k\"]>=0).astype(int)\n",
    "\n",
    "# Fixed Effects and controls\n",
    "def run_panel_ols(df, Xcols):\n",
    "    df_idx = df.set_index([ID_COL, DATE_COL]).sort_index()\n",
    "    use_ctrls = [c for c in BASE_CTRLS if c in df_idx.columns and df_idx[c].nunique(dropna=True)>1]\n",
    "    X = df_idx[Xcols + use_ctrls]\n",
    "    Y = df_idx[\"log_price\"]\n",
    "    mod = PanelOLS(Y, X, entity_effects=True, time_effects=True, drop_absorbed=True)\n",
    "    res = mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "    return res\n",
    "\n",
    "\n",
    "# A) Average post-effect (k≥0) : Continuous distance gradient（Linear & quadratic）\n",
    "\n",
    "# linear：(d) = b0 + b1 * d （d in [0,2]）\n",
    "stacked[\"G0\"] = stacked[\"near2\"] * stacked[\"post\"]\n",
    "stacked[\"G1\"] = stacked[\"near2\"] * stacked[\"dist_in2_c\"] * stacked[\"post\"]\n",
    "\n",
    "\n",
    "X_cont = [\"G0\",\"G1\"]  \n",
    "res_cont = run_panel_ols(stacked, X_cont)\n",
    "print(\"\\n=== A Continuous distance (average post-effect) - Linear model ===\")\n",
    "print(res_cont.summary)\n",
    "\n",
    "# Prediction: Plot effect with 95%CI on d∈[0,2]\n",
    "def pred_effect_continuous(res, d_grid, quadratic=False):\n",
    "    # beta = [b0, b1(, b2)]\n",
    "    names = res.params.index\n",
    "    have_quad = quadratic and (\"G2\" in names)\n",
    "    b = res.params.loc[[\"G0\",\"G1\"] + ([\"G2\"] if have_quad else [])].values\n",
    "    cov = res.cov.loc[[\"G0\",\"G1\"] + ([\"G2\"] if have_quad else []), [\"G0\",\"G1\"] + ([\"G2\"] if have_quad else [])].values\n",
    "    eff, lo, hi = [], [], []\n",
    "    for d in d_grid:\n",
    "        if have_quad:\n",
    "            v = np.array([1.0, d, d*d])\n",
    "        else:\n",
    "            v = np.array([1.0, d])\n",
    "        m = float(v @ b)\n",
    "        se = float(np.sqrt(v @ cov @ v))\n",
    "        eff.append(m); lo.append(m - 1.96*se); hi.append(m + 1.96*se)\n",
    "    return np.array(eff), np.array(lo), np.array(hi)\n",
    "\n",
    "d_grid = np.linspace(0, 2, 41)\n",
    "eff, lo, hi = pred_effect_continuous(res_cont, d_grid, quadratic=False)\n",
    "\n",
    "plt.figure(figsize=(6,4.2))\n",
    "plt.plot(d_grid, eff, label=\"Avg post effect (≤2km)\")\n",
    "plt.fill_between(d_grid, lo, hi, alpha=0.25, label=\"95% CI\")\n",
    "plt.axhline(0, color=\"black\", lw=1)\n",
    "plt.xlabel(\"Distance within 2 km (km)\")\n",
    "plt.ylabel(\"Effect on log(price) relative to >2 km\")\n",
    "plt.title(\"Continuous Distance Gradient (Avg post, ≤2km vs >2km control)\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# Output point estimates with d=0.5, 1.0, and 1.5 (Easy to compare with segment plots)\n",
    "for dd in [0.5, 1.0, 1.5]:\n",
    "    e, l, u = pred_effect_continuous(res_cont, np.array([dd]), quadratic=False)\n",
    "    print(f\"d={dd:.1f} km -> est={float(e):.4f}, 95%CI=({float(l):.4f},{float(u):.4f})\")\n",
    "\n",
    "# Distance centralization (centered at 1 km)\n",
    "stacked[\"dist_c\"]  = stacked[\"dist_in2\"] - 1.0     # in [-1, +1]\n",
    "stacked[\"dist_c2\"] = stacked[\"dist_c\"]**2\n",
    "\n",
    "# Quadratic form：G0 + G1*d_c + G2*d_c^2 \n",
    "stacked[\"G0\"] = stacked[\"near2\"] * stacked[\"post\"]\n",
    "stacked[\"G1\"] = stacked[\"near2\"] * stacked[\"dist_c\"]  * stacked[\"post\"]\n",
    "stacked[\"G2\"] = stacked[\"near2\"] * stacked[\"dist_c2\"] * stacked[\"post\"]\n",
    "\n",
    "def run_panel_ols(df, Xcols, BASE_CTRLS):\n",
    "    df_idx = df.set_index([\"lsoa21cd\",\"date\"]).sort_index()\n",
    "    use_ctrls = [c for c in BASE_CTRLS if c in df_idx.columns and df_idx[c].nunique(dropna=True)>1]\n",
    "    X = df_idx[Xcols + use_ctrls].copy()\n",
    "    \n",
    "    keep = [c for c in X.columns if X[c].std(skipna=True) > 0]\n",
    "    X = X[keep]\n",
    "    Y = df_idx[\"log_price\"]\n",
    "    mod = PanelOLS(Y, X, entity_effects=True, time_effects=True, drop_absorbed=True)\n",
    "    return mod.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "\n",
    "res_cont_q = run_panel_ols(stacked, [\"G0\",\"G1\",\"G2\"], BASE_CTRLS)\n",
    "print(\"\\n=== A Quadratic（Avg post, ≤2km vs >2km）===\")\n",
    "print(res_cont_q.summary)\n",
    "\n",
    "# d∈[0,2] → d_c = d - 1\n",
    "def pred_effect_continuous_quadratic(res, d_grid):\n",
    "    names = res.params.index\n",
    "    cols  = [c for c in [\"G0\",\"G1\",\"G2\"] if c in names]\n",
    "    b = res.params.loc[cols].values\n",
    "    V = res.cov.loc[cols, cols].values\n",
    "    eff, lo, hi = [], [], []\n",
    "    for d in d_grid:\n",
    "        dc  = d - 1.0\n",
    "        v   = np.array([1.0, dc, dc*dc])[:len(cols)]\n",
    "        m   = float(v @ b)\n",
    "        se  = float(np.sqrt(v @ V @ v))\n",
    "        eff.append(m); lo.append(m-1.96*se); hi.append(m+1.96*se)\n",
    "    return np.array(eff), np.array(lo), np.array(hi)\n",
    "\n",
    "d_grid = np.linspace(0, 2, 41)\n",
    "eff, lo, hi = pred_effect_continuous_quadratic(res_cont_q, d_grid)\n",
    "\n",
    "plt.figure(figsize=(6.2,4.2))\n",
    "plt.plot(d_grid, eff, label=\"Avg post effect (≤2km)\")\n",
    "plt.fill_between(d_grid, lo, hi, alpha=0.25, label=\"95% CI\")\n",
    "plt.axhline(0, color=\"black\", lw=1)\n",
    "plt.xlabel(\"Distance within 2 km (km)\")\n",
    "plt.ylabel(\"Effect on log(price) relative to >2 km\")\n",
    "plt.title(\"Continuous Distance Gradient — Quadratic (Avg post)\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# Print a few representative points (avoid scalar [0] with DeprecationWarning)\n",
    "for dd in [0.0, 0.5, 1.0, 1.5, 2.0]:\n",
    "    e, l, h = pred_effect_continuous_quadratic(res_cont_q, np.array([dd]))\n",
    "    print(f\"d={dd:.1f} km -> est={e[0]:.4f}, 95%CI=({l[0]:.4f},{h[0]:.4f})\")\n",
    "\n",
    "\n",
    "# B Dynamic continuous Distance (Event study)\n",
    "# Near ≤2km vs >2km，Estimate \"intercept + slope\" for each k\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from linearmodels.panel import PanelOLS\n",
    "\n",
    "# 1) Two types of variables are generated for each k:\n",
    "#    EV{k}_0: (k==K and near2==1) 0/1 -- represents \"intercept difference between ≤2km and >2km\"\n",
    "#    EV{k}_1: (k==K and near2==1) * dist_in2_c -- means \"marginal change (slope) of the effect on distance\"\n",
    "k_min, k_max = -WINDOW, WINDOW\n",
    "for kk in range(k_min, k_max + 1):\n",
    "    if kk == -1:\n",
    "        continue\n",
    "    mask = ((stacked[\"k\"] == kk) & (stacked[\"near2\"] == 1))\n",
    "    stacked[f\"EV{kk}_0\"] = mask.astype(int)\n",
    "    stacked[f\"EV{kk}_1\"] = mask.astype(int) * stacked[\"dist_in2_c\"]  \n",
    "\n",
    "# 2) The regression data is assembled and constant/all-zero columns are automatically eliminated\n",
    "ev_cols_dyn = []\n",
    "for kk in range(k_min, k_max + 1):\n",
    "    if kk == -1:\n",
    "        continue\n",
    "    ev_cols_dyn += [f\"EV{kk}_0\", f\"EV{kk}_1\"]\n",
    "\n",
    "df_idx = stacked.set_index([ID_COL, DATE_COL]).sort_index()\n",
    "\n",
    "# List of control variables\n",
    "use_ctrls = [c for c in BASE_CTRLS if c in df_idx.columns and df_idx[c].nunique(dropna=True) > 1]\n",
    "\n",
    "Xdyn_full = df_idx[ev_cols_dyn + use_ctrls].copy()\n",
    "Ydyn = df_idx[\"log_price\"]\n",
    "\n",
    "\n",
    "keep_cols = [c for c in Xdyn_full.columns if Xdyn_full[c].std(skipna=True) > 0]\n",
    "Xdyn = Xdyn_full[keep_cols]\n",
    "\n",
    "mod_dyn = PanelOLS(Ydyn, Xdyn, entity_effects=True, time_effects=True, drop_absorbed=True)\n",
    "res_dyn = mod_dyn.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "print(\"\\n=== B Dynamic Continuous Distance (Event Study) - Linear models ===\")\n",
    "print(res_dyn.summary)\n",
    "\n",
    "# 3) Draw the effect-distance curve at k=0,4,8 (we can change this to observe more situation)\n",
    "def extract_k_curve(res, kk, d_grid):\n",
    "    n0, n1 = f\"EV{kk}_0\", f\"EV{kk}_1\"\n",
    "    if (n0 not in res.params.index) or (n1 not in res.params.index):\n",
    "        return None\n",
    "    b0 = res.params[n0]; b1 = res.params[n1]\n",
    "    cov = res.cov.loc[[n0, n1], [n0, n1]].values\n",
    "    eff, lo, hi = [], [], []\n",
    "    for d in d_grid:\n",
    "        v = np.array([1.0, d])\n",
    "        m = float(v @ np.array([b0, b1]))\n",
    "        se = float(np.sqrt(v @ cov @ v))\n",
    "        eff.append(m); lo.append(m - 1.96 * se); hi.append(m + 1.96 * se)\n",
    "    return np.array(eff), np.array(lo), np.array(hi)\n",
    "\n",
    "d_grid = np.linspace(0, 2, 41)\n",
    "plt.figure(figsize=(9, 4.2))\n",
    "for kk in [0, 4, 8]:\n",
    "    curves = extract_k_curve(res_dyn, kk, d_grid)\n",
    "    if curves is None:\n",
    "        continue\n",
    "    eff_k, lo_k, hi_k = curves\n",
    "    plt.plot(d_grid, eff_k, label=f\"k={kk}\")\n",
    "    plt.fill_between(d_grid, lo_k, hi_k, alpha=0.15)\n",
    "plt.axhline(0, color=\"black\", lw=1)\n",
    "plt.xlabel(\"Distance within 2 km (km)\")\n",
    "plt.ylabel(\"Effect on log(price) relative to >2 km\")\n",
    "plt.title(\"Event-time Distance Gradient (k=0,4,8)\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# 4) Wald Test\n",
    "\n",
    "def wald_pretrend_dynamic(res, part=\"intercept\", pre_max=-2):\n",
    "    \"\"\"\n",
    "    part: 'intercept' test EV{k}_0；'slope' test EV{k}_1\n",
    "    pre_max: The preambles with k<=pre_max are tested together\n",
    "    \"\"\"\n",
    "    idx = res.params.index\n",
    "    if part == \"intercept\":\n",
    "        varnames = [f\"EV{kk}_0\" for kk in range(k_min, pre_max + 1) if kk != -1 and f\"EV{kk}_0\" in idx]\n",
    "        label = \"Intercept (EV_k_0)\"\n",
    "    else:\n",
    "        varnames = [f\"EV{kk}_1\" for kk in range(k_min, pre_max + 1) if kk != -1 and f\"EV{kk}_1\" in idx]\n",
    "        label = \"Slope (EV_k_1)\"\n",
    "    if not varnames:\n",
    "        print(f\"[Pretrend] {label}: no pre-k terms found.\")\n",
    "        return None\n",
    "    R = np.vstack([np.eye(len(idx))[idx.get_loc(v)] for v in varnames])\n",
    "    q = np.zeros(len(varnames))\n",
    "    w = res.wald_test(R, q)\n",
    "    print(f\"[Pretrend] {label} chi2={w.stat:.2f}, p={w.pval:.4f}\")\n",
    "    return w\n",
    "\n",
    "\n",
    "wald_pretrend_dynamic(res_dyn, part=\"intercept\", pre_max=-2)\n",
    "wald_pretrend_dynamic(res_dyn, part=\"slope\",     pre_max=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d80fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate three types of variables for each k: EV{k}_0, EV{k}_1, EV{k}_2.\n",
    "k_min, k_max = -WINDOW, WINDOW\n",
    "for kk in range(k_min, k_max+1):\n",
    "    if kk == -1:\n",
    "        continue\n",
    "    mask = ((stacked[\"k\"]==kk) & (stacked[\"near2\"]==1))\n",
    "    stacked[f\"EV{kk}_0\"] = mask.astype(int)\n",
    "    stacked[f\"EV{kk}_1\"] = mask.astype(int) * stacked[\"dist_c\"]\n",
    "    stacked[f\"EV{kk}_2\"] = mask.astype(int) * stacked[\"dist_c2\"]\n",
    "\n",
    "\n",
    "ev_cols_dyn_q = []\n",
    "for kk in range(k_min, k_max+1):\n",
    "    if kk == -1:\n",
    "        continue\n",
    "    ev_cols_dyn_q += [f\"EV{kk}_0\", f\"EV{kk}_1\", f\"EV{kk}_2\"]\n",
    "\n",
    "df_idx = stacked.set_index([\"lsoa21cd\",\"date\"]).sort_index()\n",
    "use_ctrls = [c for c in BASE_CTRLS if c in df_idx.columns and df_idx[c].nunique(dropna=True)>1]\n",
    "Xdyn = df_idx[ev_cols_dyn_q + use_ctrls].copy()\n",
    "\n",
    "keep = [c for c in Xdyn.columns if Xdyn[c].std(skipna=True) > 0]\n",
    "Xdyn = Xdyn[keep]\n",
    "Ydyn = df_idx[\"log_price\"]\n",
    "\n",
    "mod_dyn_q = PanelOLS(Ydyn, Xdyn, entity_effects=True, time_effects=True, drop_absorbed=True)\n",
    "res_dyn_q = mod_dyn_q.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "print(\"\\n=== B Quadratic（Dynamic, ≤2km vs >2km）===\")\n",
    "print(res_dyn_q.summary)\n",
    "\n",
    "# Extract the \"effect-distance curve\" for the given k.Extract the \"effect-distance curve\" for the given k.\n",
    "def extract_k_curve_quadratic(res, kk, d_grid):\n",
    "    names = res.params.index\n",
    "    cols  = [c for c in [f\"EV{kk}_0\", f\"EV{kk}_1\", f\"EV{kk}_2\"] if c in names]\n",
    "    if len(cols) < 2:   # At least _0 and _1 are required.\n",
    "        return None\n",
    "    b = res.params.loc[cols].values\n",
    "    V = res.cov.loc[cols, cols].values\n",
    "    eff, lo, hi = [], [], []\n",
    "    for d in d_grid:\n",
    "        dc  = d - 1.0\n",
    "        v   = np.array([1.0, dc, dc*dc])[:len(cols)]\n",
    "        m   = float(v @ b)\n",
    "        se  = float(np.sqrt(v @ V @ v))\n",
    "        eff.append(m); lo.append(m-1.96*se); hi.append(m+1.96*se)\n",
    "    return np.array(eff), np.array(lo), np.array(hi)\n",
    "\n",
    "# Draw the quadratic curves for k = 0, 4, 8\n",
    "d_grid = np.linspace(0, 2, 41)\n",
    "plt.figure(figsize=(9,4.2))\n",
    "for kk, lab in zip([0,4,8], [\"k=0\",\"k=4\",\"k=8\"]):\n",
    "    curves = extract_k_curve_quadratic(res_dyn_q, kk, d_grid)\n",
    "    if curves is None: \n",
    "        continue\n",
    "    e,l,h = curves\n",
    "    plt.plot(d_grid, e, label=lab)\n",
    "    plt.fill_between(d_grid, l, h, alpha=0.15)\n",
    "plt.axhline(0, color=\"black\", lw=1)\n",
    "plt.xlabel(\"Distance within 2 km (km)\")\n",
    "plt.ylabel(\"Effect on log(price) relative to >2 km\")\n",
    "plt.title(\"Event-time Distance Gradient — Quadratic (k=0,4,8)\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# Dynamic Leading Joint Test: Whether the intercept/first-order/second-order are jointly equal to 0 when k ≤ -2Dynamic pretest joint test: intercept/first-order/second-order in k ≤ -2 whether jointly equal to 0\n",
    "def wald_pretrend_dyn_part(res, part=\"intercept\", pre_max=-2):\n",
    "    idx = res.params.index\n",
    "    if part==\"intercept\":\n",
    "        vars_ = [f\"EV{kk}_0\" for kk in range(k_min, pre_max+1) if kk != -1 and f\"EV{kk}_0\" in idx]\n",
    "        label = \"Intercept (EV_k_0)\"\n",
    "    elif part==\"slope\":\n",
    "        vars_ = [f\"EV{kk}_1\" for kk in range(k_min, pre_max+1) if kk != -1 and f\"EV{kk}_1\" in idx]\n",
    "        label = \"Linear slope (EV_k_1)\"\n",
    "    else:\n",
    "        vars_ = [f\"EV{kk}_2\" for kk in range(k_min, pre_max+1) if kk != -1 and f\"EV{kk}_2\" in idx]\n",
    "        label = \"Quadratic term (EV_k_2)\"\n",
    "    if not vars_:\n",
    "        print(f\"[Pretrend] {label}: no pre-k terms.\")\n",
    "        return None\n",
    "    R = np.vstack([np.eye(len(idx))[idx.get_loc(v)] for v in vars_])\n",
    "    q = np.zeros(len(vars_))\n",
    "    w = res.wald_test(R, q)\n",
    "    print(f\"[Pretrend] {label} chi2={w.stat:.2f}, p={w.pval:.4f}\")\n",
    "    return w\n",
    "\n",
    "wald_pretrend_dyn_part(res_dyn_q, \"intercept\", pre_max=-2)\n",
    "wald_pretrend_dyn_part(res_dyn_q, \"slope\",     pre_max=-2)\n",
    "wald_pretrend_dyn_part(res_dyn_q, \"quad\",      pre_max=-2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transport-houseprice-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
